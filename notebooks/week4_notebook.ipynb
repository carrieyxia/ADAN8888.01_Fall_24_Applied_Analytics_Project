{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Notebook: Data Preprocessing\n",
    "The goal of this week's assignment is to continue to preprocess our data by cleaning it, treating issues such as outliers and missing values, transforming variables, and making the data model-ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "\n",
    "uber_file_path = os.path.join(raw_data_folder, \"uber.csv.zip\")\n",
    "lyft_file_path = os.path.join(raw_data_folder, \"lyft.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uber file extracted to: /Users/carriexia/Documents/GitHub/ADAN8888.01_Fall_24_Applied_Analytics_Project/data/raw\n",
      "Lyft file extracted to: /Users/carriexia/Documents/GitHub/ADAN8888.01_Fall_24_Applied_Analytics_Project/data/raw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.exists(uber_file_path):\n",
    "    with zipfile.ZipFile(uber_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(raw_data_folder)\n",
    "    print(f\"Uber file extracted to: {raw_data_folder}\")\n",
    "else:\n",
    "    print(f\"Uber file not found: {uber_file_path}\")\n",
    "\n",
    "if os.path.exists(lyft_file_path):\n",
    "    with zipfile.ZipFile(lyft_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(raw_data_folder)\n",
    "    print(f\"Lyft file extracted to: {raw_data_folder}\")\n",
    "else:\n",
    "    print(f\"Lyft file not found: {lyft_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_csv_path = os.path.join(raw_data_folder, \"uber.csv\")\n",
    "lyft_csv_path = os.path.join(raw_data_folder, \"lyft.csv\")\n",
    "\n",
    "uber_df = pd.read_csv(uber_csv_path)\n",
    "lyft_df = pd.read_csv(lyft_csv_path)\n",
    "    \n",
    "df = pd.concat([uber_df, lyft_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Test Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df):\n",
    "    # Suffle the dataset and calculate the size of validation and test sets\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123)\n",
    "\n",
    "    val_size = int(len(df) * 0.2)\n",
    "    test_size = int(len(df) * 0.1)\n",
    "\n",
    "    # Select rows based on the val_size and test_size to store as train set, val set, and test set\n",
    "    train_df = df.iloc[val_size + test_size:]\n",
    "    val_df = df.iloc[:val_size]\n",
    "    test_df = df.iloc[val_size:val_size + test_size]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Imputation\n",
    "Uber Taxi Fee Breakdown\n",
    " - base fare: $2.60 for first 1/7 mile\n",
    " - per minute fare: $0.47\n",
    " - per mile: $2.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_price_calculator(distance, time):\n",
    "    base_fare = 2.60\n",
    "    per_min_fare = 0.47\n",
    "    per_mile_fare = 2.8\n",
    "    price = base_fare + distance * per_mile_fare + time * per_min_fare\n",
    "    return price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have one time stamp rather the duration of each ride. We will need to figure out a way to estimate the time costed for each Taxi ride for a more accurate imputation. Here are the Steps.\n",
    "\n",
    "1. Get the unique records for locations as a lst and save the unique combination of sources as a csv\n",
    "2. Get the longtitude and latitude for these loctaions and save it as a dict with location as the key and value being [lat, long]\n",
    "3. Read the csv and create sourece latitude, soure longtitude, desitination latitude, destination longtitude columns based on the location dict\n",
    "4. Use the Mapbox Direction API to pull time estimated by driving\n",
    "5. Save the csv with source, destination, time_estimated\n",
    "\n",
    "Please refer to the code folder to get the code for how we get the estimated duration for the taxi rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['North End' 'West End' 'Beacon Hill' 'South Station' 'North Station'\n",
      " 'Fenway' 'Boston University' 'Back Bay' 'Theatre District'\n",
      " 'Northeastern University' 'Financial District' 'Haymarket Square']\n"
     ]
    }
   ],
   "source": [
    "unique_combos = df[[\"source\",\"destination\"]].drop_duplicates()\n",
    "unique_combos_dir = os.path.join(interim_data_folder, \"unique_combo.csv\")\n",
    "unique_combos.to_csv(unique_combos_dir)\n",
    "\n",
    "locations = pd.unique(df[[\"source\",\"destination\"]].values.ravel())\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longtitude_latitude(location):\n",
    "    # calling the Nominatim tool and create Nominatim class\n",
    "    loc = Nominatim(user_agent=\"Geopy Library\")\n",
    "    location = location+\", Boston\"\n",
    "    getLoc = loc.geocode(location)\n",
    "    return getLoc.latitude, getLoc.longitude\n",
    "\n",
    "location_dict = {}\n",
    "\n",
    "for location in locations:\n",
    "    lat, long = get_longtitude_latitude(location)\n",
    "    if lat is not None and long is not None:\n",
    "        location_dict[location] = [lat, long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_combos[\"source_lat\"] = unique_combos['source'].apply(lambda x: location_dict[x][0])\n",
    "unique_combos[\"source_long\"] = unique_combos['source'].apply(lambda x: location_dict[x][1])\n",
    "\n",
    "unique_combos[\"destination_lat\"] = unique_combos['destination'].apply(lambda x: location_dict[x][0])\n",
    "unique_combos[\"destination_long\"] = unique_combos['destination'].apply(lambda x: location_dict[x][1])\n",
    "\n",
    "ride_locations_dir = os.path.join(interim_data_folder, \"ride_locations.csv\")\n",
    "df.to_csv(ride_locations_dir, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  `get_eta` function requires api_key, so I saved the dataframe locally for reviewing convinience. Pleaser refer to the `time_calulator.py` under the codes folder for more details how the time was imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>eta_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North End</td>\n",
       "      <td>West End</td>\n",
       "      <td>7.751050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>South Station</td>\n",
       "      <td>10.896667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Station</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>13.937950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North End</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>12.600567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>15.743100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source    destination  eta_minutes\n",
       "0          North End       West End     7.751050\n",
       "1        Beacon Hill  South Station    10.896667\n",
       "2      North Station         Fenway    13.937950\n",
       "3          North End    Beacon Hill    12.600567\n",
       "4  Boston University  North Station    15.743100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rides_with_eta = os.path.join(interim_data_folder, \"rides_with_etas.csv\")\n",
    "time_df = pd.read_csv(rides_with_eta)\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, time_df[['source', 'destination', 'eta_minutes']], on=['source', 'destination'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>datetime</th>\n",
       "      <th>timezone</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>...</th>\n",
       "      <th>uvIndexTime</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>temperatureMinTime</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMaxTime</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>apparentTemperatureMinTime</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMaxTime</th>\n",
       "      <th>eta_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>009e9c53-074d-43cf-aef2-0fbc7a47ed3d</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-30 22:13:01</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>West End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>...</td>\n",
       "      <td>1543593600</td>\n",
       "      <td>28.79</td>\n",
       "      <td>1543579200</td>\n",
       "      <td>42.52</td>\n",
       "      <td>1543600800</td>\n",
       "      <td>26.41</td>\n",
       "      <td>1543575600</td>\n",
       "      <td>40.53</td>\n",
       "      <td>1543611600</td>\n",
       "      <td>7.75105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23f145da-f0c1-4d1f-a184-496bc003a7db</td>\n",
       "      <td>1.544698e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-13 10:50:11</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>West End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>...</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.83</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.79</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.85</td>\n",
       "      <td>1544734800</td>\n",
       "      <td>7.75105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>357559cb-8c58-4278-a41a-e33b2e0997a3</td>\n",
       "      <td>1.544729e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-13 19:15:03</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>West End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>...</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.83</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.79</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.85</td>\n",
       "      <td>1544734800</td>\n",
       "      <td>7.75105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50ef1165-9d23-416c-a65c-18906207b295</td>\n",
       "      <td>1.545005e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-16 23:55:11</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>West End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>...</td>\n",
       "      <td>1544979600</td>\n",
       "      <td>39.22</td>\n",
       "      <td>1544954400</td>\n",
       "      <td>43.83</td>\n",
       "      <td>1544990400</td>\n",
       "      <td>33.98</td>\n",
       "      <td>1545019200</td>\n",
       "      <td>38.38</td>\n",
       "      <td>1544986800</td>\n",
       "      <td>7.75105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91c4861c-1780-42b0-bca1-bbd64a422cc3</td>\n",
       "      <td>1.544748e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-14 00:40:07</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>West End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>...</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.83</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.79</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.85</td>\n",
       "      <td>1544734800</td>\n",
       "      <td>7.75105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id     timestamp  hour  day  month  \\\n",
       "0  009e9c53-074d-43cf-aef2-0fbc7a47ed3d  1.543616e+09    22   30     11   \n",
       "1  23f145da-f0c1-4d1f-a184-496bc003a7db  1.544698e+09    10   13     12   \n",
       "2  357559cb-8c58-4278-a41a-e33b2e0997a3  1.544729e+09    19   13     12   \n",
       "3  50ef1165-9d23-416c-a65c-18906207b295  1.545005e+09    23   16     12   \n",
       "4  91c4861c-1780-42b0-bca1-bbd64a422cc3  1.544748e+09     0   14     12   \n",
       "\n",
       "              datetime          timezone     source destination cab_type  ...  \\\n",
       "0  2018-11-30 22:13:01  America/New_York  North End    West End     Uber  ...   \n",
       "1  2018-12-13 10:50:11  America/New_York  North End    West End     Uber  ...   \n",
       "2  2018-12-13 19:15:03  America/New_York  North End    West End     Uber  ...   \n",
       "3  2018-12-16 23:55:11  America/New_York  North End    West End     Uber  ...   \n",
       "4  2018-12-14 00:40:07  America/New_York  North End    West End     Uber  ...   \n",
       "\n",
       "  uvIndexTime temperatureMin  temperatureMinTime  temperatureMax  \\\n",
       "0  1543593600          28.79          1543579200           42.52   \n",
       "1  1544716800          18.29          1544688000           33.83   \n",
       "2  1544716800          18.29          1544688000           33.83   \n",
       "3  1544979600          39.22          1544954400           43.83   \n",
       "4  1544716800          18.29          1544688000           33.83   \n",
       "\n",
       "   temperatureMaxTime  apparentTemperatureMin  apparentTemperatureMinTime  \\\n",
       "0          1543600800                   26.41                  1543575600   \n",
       "1          1544731200                   13.79                  1544688000   \n",
       "2          1544731200                   13.79                  1544688000   \n",
       "3          1544990400                   33.98                  1545019200   \n",
       "4          1544731200                   13.79                  1544688000   \n",
       "\n",
       "   apparentTemperatureMax  apparentTemperatureMaxTime eta_minutes  \n",
       "0                   40.53                  1543611600     7.75105  \n",
       "1                   32.85                  1544734800     7.75105  \n",
       "2                   32.85                  1544734800     7.75105  \n",
       "3                   38.38                  1544986800     7.75105  \n",
       "4                   32.85                  1544734800     7.75105  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['name'] == 'Taxi', 'price'] = df.loc[df['name'] == 'Taxi'].apply(\n",
    "    lambda row: taxi_price_calculator(row['distance'], row['eta_minutes']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "timestamp                      0\n",
       "hour                           0\n",
       "day                            0\n",
       "month                          0\n",
       "datetime                       0\n",
       "timezone                       0\n",
       "source                         0\n",
       "destination                    0\n",
       "cab_type                       0\n",
       "product_id                     0\n",
       "name                           0\n",
       "price                          0\n",
       "distance                       0\n",
       "surge_multiplier               0\n",
       "latitude                       0\n",
       "longitude                      0\n",
       "temperature                    0\n",
       "apparentTemperature            0\n",
       "short_summary                  0\n",
       "long_summary                   0\n",
       "precipIntensity                0\n",
       "precipProbability              0\n",
       "humidity                       0\n",
       "windSpeed                      0\n",
       "windGust                       0\n",
       "windGustTime                   0\n",
       "visibility                     0\n",
       "temperatureHigh                0\n",
       "temperatureHighTime            0\n",
       "temperatureLow                 0\n",
       "temperatureLowTime             0\n",
       "apparentTemperatureHigh        0\n",
       "apparentTemperatureHighTime    0\n",
       "apparentTemperatureLow         0\n",
       "apparentTemperatureLowTime     0\n",
       "icon                           0\n",
       "dewPoint                       0\n",
       "pressure                       0\n",
       "windBearing                    0\n",
       "cloudCover                     0\n",
       "uvIndex                        0\n",
       "visibility.1                   0\n",
       "ozone                          0\n",
       "sunriseTime                    0\n",
       "sunsetTime                     0\n",
       "moonPhase                      0\n",
       "precipIntensityMax             0\n",
       "uvIndexTime                    0\n",
       "temperatureMin                 0\n",
       "temperatureMinTime             0\n",
       "temperatureMax                 0\n",
       "temperatureMaxTime             0\n",
       "apparentTemperatureMin         0\n",
       "apparentTemperatureMinTime     0\n",
       "apparentTemperatureMax         0\n",
       "apparentTemperatureMaxTime     0\n",
       "eta_minutes                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi = df[df[\"name\" ]== \"Taxi\"]\n",
    "df_taxi.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('eta_minutes', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in 'price' after imputing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "df_na = df[df['price'].isna()]\n",
    "missing_percentage_after_imputing = df['price'].isna().sum() / len(df) * 100\n",
    "print(f\"Percentage of missing values in 'price' after imputing: {missing_percentage_after_imputing:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
