{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Notebook: Feature Engineering\n",
    "The goal of this week's assignment is to engineer new features and reduce the dimensionality of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "\n",
    "uber_file_path = os.path.join(raw_data_folder, \"uber.csv.zip\")\n",
    "lyft_file_path = os.path.join(raw_data_folder, \"lyft.csv.zip\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if os.path.exists(uber_file_path):\n",
    "    with zipfile.ZipFile(uber_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(raw_data_folder)\n",
    "    print(f\"Uber file extracted to: {raw_data_folder}\")\n",
    "else:\n",
    "    print(f\"Uber file not found: {uber_file_path}\")\n",
    "\n",
    "if os.path.exists(lyft_file_path):\n",
    "    with zipfile.ZipFile(lyft_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(raw_data_folder)\n",
    "    print(f\"Lyft file extracted to: {raw_data_folder}\")\n",
    "else:\n",
    "    print(f\"Lyft file not found: {lyft_file_path}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "uber_csv_path = os.path.join(raw_data_folder, \"uber.csv\")\n",
    "lyft_csv_path = os.path.join(raw_data_folder, \"lyft.csv\")\n",
    "\n",
    "uber_df = pd.read_csv(uber_csv_path)\n",
    "lyft_df = pd.read_csv(lyft_csv_path)\n",
    "    \n",
    "df = pd.concat([uber_df, lyft_df], ignore_index=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'timestamp', 'hour', 'day', 'month', 'timezone', 'source',\n",
      "       'destination', 'cab_type', 'product_id', 'name', 'price', 'distance',\n",
      "       'surge_multiplier', 'latitude', 'longitude', 'temperature',\n",
      "       'apparentTemperature', 'short_summary', 'long_summary',\n",
      "       'precipIntensity', 'precipProbability', 'humidity', 'windSpeed',\n",
      "       'windGust', 'windGustTime', 'visibility', 'temperatureHigh',\n",
      "       'temperatureHighTime', 'temperatureLow', 'temperatureLowTime',\n",
      "       'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
      "       'apparentTemperatureLow', 'apparentTemperatureLowTime', 'icon',\n",
      "       'dewPoint', 'pressure', 'windBearing', 'cloudCover', 'uvIndex',\n",
      "       'visibility.1', 'ozone', 'sunriseTime', 'sunsetTime', 'moonPhase',\n",
      "       'precipIntensityMax', 'uvIndexTime', 'temperatureMin',\n",
      "       'temperatureMinTime', 'temperatureMax', 'temperatureMaxTime',\n",
      "       'apparentTemperatureMin', 'apparentTemperatureMinTime',\n",
      "       'apparentTemperatureMax', 'apparentTemperatureMaxTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe.\n",
    "df = pd.read_csv('rawSampledData.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training, testing, and validation sets\n",
    "- training set is 70% of the dataframe\n",
    "- validation set is 20% of the dataframe\n",
    "- test set is 10% of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df):\n",
    "    # Shuffle the dataset and calculate the size of validation and test sets\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123)\n",
    "\n",
    "    val_size = int(len(df) * 0.2)\n",
    "    test_size = int(len(df) * 0.1)\n",
    "\n",
    "    # Select rows based on the val_size and test_size to store as train set, val set, and test set\n",
    "    train_df = df.iloc[val_size + test_size:]\n",
    "    val_df = df.iloc[:val_size]\n",
    "    test_df = df.iloc[val_size:val_size + test_size]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = train_val_test_split(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['timezone', 'product_id', 'visibility.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rush Hour\n",
    "# 6-9 AM or 4-6 PM \n",
    "df['rush_hour'] = df['hour'].apply(lambda x: 1 if (6 <= x <= 9 or 16 <= x <= 18) else 0)\n",
    "\n",
    "# Weekend \n",
    "# Saturday or Sunday\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['weekend'] = df['datetime'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Holiday\n",
    "holidays = ['2018-11-11', '2018-11-22','2018-12-24','2018-12-25','2018-12-31'] \n",
    "df['holiday'] = df['datetime'].dt.date.astype(str).isin(holidays).astype(int)\n",
    "\n",
    "# Extreme Weather\n",
    "# Apparent temperature less than 20 degrees AND Wind gust above 25)\n",
    "df['extreme_weather'] = df.apply(lambda row: 1 if row['apparentTemperature'] < 20 and row['windGust'] > 25 else 0, axis=1)\n",
    "\n",
    "# Snow\n",
    "# Below 32 degrees and precipitation intensity above 0\n",
    "df['snow'] = df.apply(lambda row: 1 if row['temperature'] < 32 and row['precipIntensity'] > 0 else 0, axis=1)\n",
    "\n",
    "# Reduced Visability\n",
    "# Visibility less than 5 miles\n",
    "df['reduced_visibility'] = df['visibility'].apply(lambda x: 1 if x < 5 else 0)\n",
    "\n",
    "# Dinner Time\n",
    "# 5-8 PM\n",
    "df['dinner_time'] = df['hour'].apply(lambda x: 1 if 17 <= x <= 20 else 0)\n",
    "\n",
    "# Friday or Saturday night\n",
    "# Friday or Saturday nights between 5 PM and 2 AM)\n",
    "df['fri_sat_night'] = df.apply(lambda row: 1 if (17 <= row['hour'] <= 23 and row['datetime'].dayofweek in [4, 5]) or \n",
    "                                          (0 <= row['hour'] <= 2 and row['datetime'].dayofweek in [5, 6]) else 0, axis=1)\n",
    "\n",
    "# Late Night\n",
    "# 10 PM -4 AM\n",
    "df['late_night'] = df['hour'].apply(lambda x: 1 if (22 <= x <= 23 or 0 <= x <= 4) else 0)\n",
    "\n",
    "# Late Night Weekend\n",
    "# Friday or Saturday nights between 10 PM and 4 AM)\n",
    "df['late_night_weekend'] = df.apply(lambda row: 1 if ((row['hour'] >= 22 and row['datetime'].dayofweek == 4) or \n",
    "                                                     (row['hour'] <= 4 and row['datetime'].dayofweek == 5) or\n",
    "                                                     (row['hour'] >= 22 and row['datetime'].dayofweek == 5) or\n",
    "                                                     (row['hour'] <= 4 and row['datetime'].dayofweek == 6)) else 0, axis=1)\n",
    "\n",
    "# Bruins or Celtics play in Boston\n",
    "bruins = ['2018-11-5','2018-11-8','2018-11-10','2018-11-11','2018-11-23','2018-11-29','2018-12-1','2018-12-8','2018-12-11','2018-12-16','2018-12-20','2018-12-22','2018-12-27'] \n",
    "celtics = ['2018-11-1','2018-11-14','2018-11-16','2018-11-17','2018-11-21','2018-11-30','2018-12-6','2018-12-10','2018-12-14','2018-12-19','2018-12-21','2018-12-23','2018-12-25']\n",
    "game_dates = bruins + celtics\n",
    "df['game_day'] = df['datetime'].apply(lambda x: 1 if x in game_dates else 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
