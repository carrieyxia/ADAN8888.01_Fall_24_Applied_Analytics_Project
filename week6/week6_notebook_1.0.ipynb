{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Notebook: Model training, hyperparameter tuning, and model evaluation\n",
    "The goal of this week's assignment is to use one modeling method with 3 different hyperparameter settings of the method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "processed_data_folder = os.path.join(data_folder, \"processed\")\n",
    "\n",
    "raw_data_file = os.path.join(raw_data_folder, 'rawSampledData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'timestamp', 'hour', 'day', 'month', 'timezone', 'source',\n",
      "       'destination', 'cab_type', 'product_id', 'name', 'price', 'distance',\n",
      "       'surge_multiplier', 'latitude', 'longitude', 'temperature',\n",
      "       'apparentTemperature', 'short_summary', 'long_summary',\n",
      "       'precipIntensity', 'precipProbability', 'humidity', 'windSpeed',\n",
      "       'windGust', 'windGustTime', 'visibility', 'temperatureHigh',\n",
      "       'temperatureHighTime', 'temperatureLow', 'temperatureLowTime',\n",
      "       'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
      "       'apparentTemperatureLow', 'apparentTemperatureLowTime', 'icon',\n",
      "       'dewPoint', 'pressure', 'windBearing', 'cloudCover', 'uvIndex',\n",
      "       'visibility.1', 'ozone', 'sunriseTime', 'sunsetTime', 'moonPhase',\n",
      "       'precipIntensityMax', 'uvIndexTime', 'temperatureMin',\n",
      "       'temperatureMinTime', 'temperatureMax', 'temperatureMaxTime',\n",
      "       'apparentTemperatureMin', 'apparentTemperatureMinTime',\n",
      "       'apparentTemperatureMax', 'apparentTemperatureMaxTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe.\n",
    "df = pd.read_csv(raw_data_file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>timezone</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>...</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>uvIndexTime</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>temperatureMinTime</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMaxTime</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>apparentTemperatureMinTime</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMaxTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-13 20:40:15</td>\n",
       "      <td>1.544734e+09</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.83</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.79</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.85</td>\n",
       "      <td>1544734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-02 09:53:05</td>\n",
       "      <td>1.543744e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>Uber</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>1543770000</td>\n",
       "      <td>36.40</td>\n",
       "      <td>1543726800</td>\n",
       "      <td>50.94</td>\n",
       "      <td>1543788000</td>\n",
       "      <td>35.78</td>\n",
       "      <td>1543748400</td>\n",
       "      <td>50.27</td>\n",
       "      <td>1543788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-28 21:53:08</td>\n",
       "      <td>1.543442e+09</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1543420800</td>\n",
       "      <td>33.70</td>\n",
       "      <td>1543399200</td>\n",
       "      <td>42.60</td>\n",
       "      <td>1543438800</td>\n",
       "      <td>29.88</td>\n",
       "      <td>1543399200</td>\n",
       "      <td>36.56</td>\n",
       "      <td>1543435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-13 05:15:05</td>\n",
       "      <td>1.544678e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>17.98</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.82</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.52</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.84</td>\n",
       "      <td>1544734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-02 09:48:00</td>\n",
       "      <td>1.543744e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Uber</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>1543770000</td>\n",
       "      <td>36.40</td>\n",
       "      <td>1543726800</td>\n",
       "      <td>50.94</td>\n",
       "      <td>1543788000</td>\n",
       "      <td>35.78</td>\n",
       "      <td>1543748400</td>\n",
       "      <td>50.27</td>\n",
       "      <td>1543788000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime     timestamp  hour  day  month          timezone  \\\n",
       "0  2018-12-13 20:40:15  1.544734e+09    20   13     12  America/New_York   \n",
       "1  2018-12-02 09:53:05  1.543744e+09     9    2     12  America/New_York   \n",
       "2  2018-11-28 21:53:08  1.543442e+09    21   28     11  America/New_York   \n",
       "3  2018-12-13 05:15:05  1.544678e+09     5   13     12  America/New_York   \n",
       "4  2018-12-02 09:48:00  1.543744e+09     9    2     12  America/New_York   \n",
       "\n",
       "                    source       destination cab_type  \\\n",
       "0         Theatre District            Fenway     Lyft   \n",
       "1              Beacon Hill  Haymarket Square     Uber   \n",
       "2  Northeastern University     North Station     Lyft   \n",
       "3                   Fenway          Back Bay     Lyft   \n",
       "4  Northeastern University       Beacon Hill     Uber   \n",
       "\n",
       "                             product_id  ... precipIntensityMax  uvIndexTime  \\\n",
       "0                             lyft_plus  ...             0.0001   1544716800   \n",
       "1  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  ...             0.0894   1543770000   \n",
       "2                                  lyft  ...             0.0000   1543420800   \n",
       "3                           lyft_luxsuv  ...             0.0001   1544716800   \n",
       "4  6d318bcc-22a3-4af6-bddd-b409bfce1546  ...             0.0894   1543770000   \n",
       "\n",
       "   temperatureMin  temperatureMinTime  temperatureMax  temperatureMaxTime  \\\n",
       "0           18.29          1544688000           33.83          1544731200   \n",
       "1           36.40          1543726800           50.94          1543788000   \n",
       "2           33.70          1543399200           42.60          1543438800   \n",
       "3           17.98          1544688000           33.82          1544731200   \n",
       "4           36.40          1543726800           50.94          1543788000   \n",
       "\n",
       "   apparentTemperatureMin  apparentTemperatureMinTime apparentTemperatureMax  \\\n",
       "0                   13.79                  1544688000                  32.85   \n",
       "1                   35.78                  1543748400                  50.27   \n",
       "2                   29.88                  1543399200                  36.56   \n",
       "3                   13.52                  1544688000                  32.84   \n",
       "4                   35.78                  1543748400                  50.27   \n",
       "\n",
       "  apparentTemperatureMaxTime  \n",
       "0                 1544734800  \n",
       "1                 1543788000  \n",
       "2                 1543435200  \n",
       "3                 1544734800  \n",
       "4                 1543788000  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training, testing, and validation sets\n",
    "- training set is 70% of the dataframe\n",
    "- validation set is 20% of the dataframe\n",
    "- test set is 10% of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df):\n",
    "    # Shuffle the dataset and calculate the size of validation and test sets\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123)\n",
    "\n",
    "    val_size = int(len(df) * 0.2)\n",
    "    test_size = int(len(df) * 0.1)\n",
    "\n",
    "    # Select rows based on the val_size and test_size to store as train set, val set, and test set\n",
    "    train_df = df.iloc[val_size + test_size:]\n",
    "    val_df = df.iloc[:val_size]\n",
    "    test_df = df.iloc[val_size:val_size + test_size]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new variables\n",
    "#### Weather-related Variable\n",
    "There are several variables, `icon`, `short_summary`, and `long_summary`, that are very similar in its context. We are thinking about combining them into one variable to reduce redundancy and dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes of icon:\n",
      "[' partly-cloudy-day ' ' rain ' ' cloudy ' ' clear-night ' ' clear-day '\n",
      " ' partly-cloudy-night ' ' fog ']\n",
      "\n",
      "Unique classes of short_summary:\n",
      "[' Mostly Cloudy ' ' Light Rain ' ' Overcast ' ' Clear ' ' Partly Cloudy '\n",
      " ' Rain ' ' Foggy ' ' Drizzle ' ' Possible Drizzle ']\n",
      "\n",
      "Unique classes of long_summary:\n",
      "[' Partly cloudy throughout the day. ' ' Light rain until evening. '\n",
      " ' Mostly cloudy throughout the day. '\n",
      " ' Rain until morning, starting again in the evening. '\n",
      " ' Light rain in the morning. ' ' Overcast throughout the day. '\n",
      " ' Foggy in the morning. ' ' Light rain in the morning and overnight. '\n",
      " ' Rain throughout the day. ' ' Possible drizzle in the morning. '\n",
      " ' Rain in the morning and afternoon. ']\n"
     ]
    }
   ],
   "source": [
    "print('Unique classes of icon:')\n",
    "print(df['icon'].unique())\n",
    "print('')\n",
    "print('Unique classes of short_summary:')\n",
    "print(df['short_summary'].unique())\n",
    "print('')\n",
    "print('Unique classes of long_summary:')\n",
    "print(df['long_summary'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can appraoch the problem is to create a custom weighting system by assigning scores to each type of weather event based on severity or relevance. We weight it by evaluating the weather conditions, considering all three variables and visibility as visibility plays a significant role in determining whether weather conditions will impact driving safety. \n",
    "\n",
    "In order to calculate the weight, we first need to understand how these variables reflect the weather on that specific date and assess how severe the conditions are for driving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = df[['icon', 'short_summary', 'long_summary']].drop_duplicates()\n",
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rain</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rain</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain in the morning and overnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icon       short_summary  \\\n",
       "1     rain          Light Rain    \n",
       "24    rain                Rain    \n",
       "33    rain             Drizzle    \n",
       "39    rain          Light Rain    \n",
       "43    rain             Drizzle    \n",
       "46    rain          Light Rain    \n",
       "85    rain          Light Rain    \n",
       "140   rain    Possible Drizzle    \n",
       "147   rain          Light Rain    \n",
       "198   rain    Possible Drizzle    \n",
       "205   rain    Possible Drizzle    \n",
       "229   rain    Possible Drizzle    \n",
       "278   rain                Rain    \n",
       "345   rain                Rain    \n",
       "\n",
       "                                          long_summary  \n",
       "1                           Light rain until evening.   \n",
       "24    Rain until morning, starting again in the eve...  \n",
       "33                         Light rain in the morning.   \n",
       "39                           Rain throughout the day.   \n",
       "43    Rain until morning, starting again in the eve...  \n",
       "46    Rain until morning, starting again in the eve...  \n",
       "85                         Light rain in the morning.   \n",
       "140                         Light rain until evening.   \n",
       "147          Light rain in the morning and overnight.   \n",
       "198   Rain until morning, starting again in the eve...  \n",
       "205                        Light rain in the morning.   \n",
       "229                          Rain throughout the day.   \n",
       "278                          Rain throughout the day.   \n",
       "345                        Light rain in the morning.   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' rain ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mostly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Overcast throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain in the morning and overnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Foggy in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Possible drizzle in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain in the morning and afternoon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          icon short_summary  \\\n",
       "2      cloudy      Overcast    \n",
       "5      cloudy      Overcast    \n",
       "6      cloudy      Overcast    \n",
       "8      cloudy      Overcast    \n",
       "16     cloudy      Overcast    \n",
       "17     cloudy      Overcast    \n",
       "28     cloudy      Overcast    \n",
       "36     cloudy      Overcast    \n",
       "89     cloudy      Overcast    \n",
       "933    cloudy      Overcast    \n",
       "2146   cloudy      Overcast    \n",
       "\n",
       "                                           long_summary  \n",
       "2                    Mostly cloudy throughout the day.   \n",
       "5      Rain until morning, starting again in the eve...  \n",
       "6                           Light rain in the morning.   \n",
       "8                         Overcast throughout the day.   \n",
       "16                   Partly cloudy throughout the day.   \n",
       "17                            Rain throughout the day.   \n",
       "28                           Light rain until evening.   \n",
       "36            Light rain in the morning and overnight.   \n",
       "89                               Foggy in the morning.   \n",
       "933                   Possible drizzle in the morning.   \n",
       "2146                Rain in the morning and afternoon.   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' cloudy ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Foggy in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Rain in the morning and afternoon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icon short_summary                                       long_summary\n",
       "32     fog         Foggy    Rain until morning, starting again in the eve...\n",
       "70     fog         Foggy                              Foggy in the morning. \n",
       "6997   fog         Foggy                 Rain in the morning and afternoon. "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' fog ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precipitation intensity between 0.1 to 0.4 in/h indicates steady rain, which may cause minor inconveniences but typically does not result in flooding. There is no indication of severe rain in our data. However, visibility below 1 mile can significantly impact driving conditions. As a result, we plan to incorporate visibility into our approach for weighting the effects of weather.\n",
    "\n",
    "- By default, every row's weather severity condition is set to 1. \n",
    "- If the rain classified as anything other than \"light\", we assign it a severity level of 3 (indicating the highest severity).\n",
    "- For all other conditions (cloudy, foggy, or light rain), we assign as severity level of 2. \n",
    "- Since there are no instances of severe rain in the dataset, we will adjust the severity score further based on visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008998</td>\n",
       "      <td>8.463778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027040</td>\n",
       "      <td>2.603025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.144700</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precipIntensity     visibility\n",
       "count    100000.000000  100000.000000\n",
       "mean          0.008998       8.463778\n",
       "std           0.027040       2.603025\n",
       "min           0.000000       0.717000\n",
       "25%           0.000000       8.432000\n",
       "50%           0.000000       9.880000\n",
       "75%           0.000000       9.996000\n",
       "max           0.144700      10.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['precipIntensity', 'visibility']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_severity(row):\n",
    "    # Initialize severity\n",
    "    severity = 1\n",
    "\n",
    "    if 'rain' in row['icon'].strip().lower():\n",
    "        # If rain is present in the icon, check for light or drizzle\n",
    "        if 'light' in row['short_summary'].lower() or 'drizzle' in row['short_summary'].lower() or \\\n",
    "           'light' in row['long_summary'].lower() or 'drizzle' in row['long_summary'].lower():\n",
    "            severity = 2  # Moderate severity for light rain or drizzle\n",
    "        else:\n",
    "            severity = 3  # Highest severity for rain without light or drizzle\n",
    "    elif 'cloudy' in row['icon'].lower() or 'fog' in row['icon'].lower():\n",
    "        severity = 2  # Moderate severity for clouds and fog\n",
    "\n",
    "    # Adjust severity based on visibility\n",
    "    if row['visibility'] < 1:  # Low visibility (less than 1)\n",
    "        severity += 1  # Increase severity by 1\n",
    "    elif row['visibility'] >= 7:  # High visibility (7 or more)\n",
    "        severity -= 1  # Decrease severity by 1\n",
    "        severity = max(severity, 1)  # Ensure severity doesn't go below 1\n",
    "\n",
    "    return severity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-related Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    # Create rush_hour feature\n",
    "    df['rush_hour'] = df['hour'].apply(lambda x: 1 if (6 <= x <= 9 or 16 <= x <= 18) else 0)\n",
    "\n",
    "    # Create weekend feature\n",
    "    df['weekend'] = df['datetime'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "    # Define game dates for Bruins and Celtics\n",
    "    bruins = [\n",
    "        '2018-11-05', '2018-11-08', '2018-11-10', '2018-11-11',\n",
    "        '2018-11-23', '2018-11-29', '2018-12-01', '2018-12-08',\n",
    "        '2018-12-11', '2018-12-16', '2018-12-20', '2018-12-22',\n",
    "        '2018-12-27'\n",
    "    ] \n",
    "    celtics = [\n",
    "        '2018-11-01', '2018-11-14', '2018-11-16', '2018-11-17',\n",
    "        '2018-11-21', '2018-11-30', '2018-12-06', '2018-12-10',\n",
    "        '2018-12-14', '2018-12-19', '2018-12-21', '2018-12-23',\n",
    "        '2018-12-25'\n",
    "    ]\n",
    "    game_dates = bruins + celtics\n",
    "\n",
    "    # Create game_day feature\n",
    "    df['game_day'] = df['datetime'].apply(lambda x: 1 if x.strftime('%Y-%m-%d') in game_dates else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_time_features(train_df)\n",
    "val_df = add_time_features(val_df)\n",
    "test_df = add_time_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Since we conducted feature engineering on the original data before preprocessing, we will run the pipeline again to get the prepare the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Imputation\n",
    "Uber Taxi Fee Breakdown\n",
    " - base fare: $2.60 for first 1/7 mile\n",
    " - per minute fare: $0.47\n",
    " - per mile: $2.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_price_calculator(distance, time):\n",
    "    base_fare = 2.60\n",
    "    per_min_fare = 0.47\n",
    "    per_mile_fare = 2.8\n",
    "    price = base_fare + distance * per_mile_fare + time * per_min_fare\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_with_eta = os.path.join(interim_data_folder, \"rides_with_etas.csv\")\n",
    "\n",
    "time_df = pd.read_csv(rides_with_eta)\n",
    "train_df = pd.merge(train_df, time_df[['source', 'destination', 'eta_minutes']], on=['source', 'destination'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['name'] == 'Taxi', 'price'] = train_df.loc[train_df['name'] == 'Taxi'].apply(\n",
    "    lambda row: taxi_price_calculator(row['distance'], row['eta_minutes']), axis=1)\n",
    "\n",
    "train_df = train_df.drop('eta_minutes', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in 'price' after imputing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "df_na = train_df[train_df['price'].isna()]\n",
    "missing_percentage_after_imputing =train_df['price'].isna().sum() / len(train_df) * 100\n",
    "print(f\"Percentage of missing values in 'price' after imputing: {missing_percentage_after_imputing:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in 'price' after imputing (validation): 0.00%\n"
     ]
    }
   ],
   "source": [
    "#Imputing missing price values in the validation set \n",
    "\n",
    "# Process the validation dataset\n",
    "val_df = pd.merge(val_df, time_df[['source', 'destination', 'eta_minutes']], on=['source', 'destination'], how='left')\n",
    "val_df.loc[val_df['name'] == 'Taxi', 'price'] = val_df.loc[val_df['name'] == 'Taxi'].apply(\n",
    "    lambda row: taxi_price_calculator(row['distance'], row['eta_minutes']), axis=1)\n",
    "val_df = val_df.drop('eta_minutes', axis=1)\n",
    "\n",
    "# Check for missing values in the validation set\n",
    "df_na_val = val_df[val_df['price'].isna()]\n",
    "missing_percentage_val = val_df['price'].isna().sum() / len(val_df) * 100\n",
    "print(f\"Percentage of missing values in 'price' after imputing (validation): {missing_percentage_val:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Uneeded Columns\n",
    "Some columns are not relevant for modeling because they function solely as unique identifiers and do not provide meaningful information for preduction purposes:\n",
    "- `id`\n",
    "- `product_id`\n",
    "\n",
    "Additionally, we also dropped `timezone` since all data is within the same timezone.\n",
    "\n",
    "`datetime` and`timestamp` were dropped to reduce redundacy with other time features.\n",
    "\n",
    "`visibility.1` is duplicated with  `visibility`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['timezone', 'datetime', 'product_id', 'visibility.1', 'timestamp','short_summary', 'long_summary', 'icon']\n",
    "\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "val_df = val_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "#### Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Columns:\n",
      "['source', 'destination', 'cab_type', 'name']\n"
     ]
    }
   ],
   "source": [
    "object_columns = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Display the object columns\n",
    "print(\"Object Columns:\")\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Encoding `source` and `destination` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['source'] = train_df['source'].str.strip().str.replace(' ', '_')\n",
    "val_df['source'] = val_df['source'].str.strip().str.replace(' ', '_')\n",
    "test_df['source'] = test_df['source'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'source' column\n",
    "train_encoded_summary = encoder.fit_transform(train_df[['source']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_summary = encoder.transform(val_df[['source']])\n",
    "test_encoded_summary = encoder.transform(test_df[['source']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_summary_df = pd.DataFrame(train_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "val_encoded_summary_df = pd.DataFrame(val_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "test_encoded_summary_df = pd.DataFrame(test_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'source' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_summary_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_summary_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the categories from the fitted OneHotEncoder for 'source'\n",
    "source_categories = encoder.categories_[0]\n",
    "\n",
    "# Initialize a new OneHotEncoder for 'destination'\n",
    "destination_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Strip leading/trailing spaces and replace blank spaces with underscores in the destination column\n",
    "train_df['destination'] = train_df['destination'].str.strip().str.replace(' ', '_')\n",
    "val_df['destination'] = val_df['destination'].str.strip().str.replace(' ', '_')\n",
    "test_df['destination'] = test_df['destination'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Fit the encoder on the training data 'destination' column\n",
    "train_encoded_destination = destination_encoder.fit_transform(train_df[['destination']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_destination = destination_encoder.transform(val_df[['destination']])\n",
    "test_encoded_destination = destination_encoder.transform(test_df[['destination']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_destination_df = pd.DataFrame(train_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "val_encoded_destination_df = pd.DataFrame(val_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "test_encoded_destination_df = pd.DataFrame(test_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'destination' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_destination_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_destination_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_destination_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding 'cab_type' and 'name' variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['name'] = train_df['name'].str.strip().str.replace(' ', '_')\n",
    "val_df['name'] = val_df['name'].str.strip().str.replace(' ', '_')\n",
    "test_df['name'] = test_df['name'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'name' column\n",
    "train_encoded_summary = encoder.fit_transform(train_df[['name']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_summary = encoder.transform(val_df[['name']])\n",
    "test_encoded_summary = encoder.transform(test_df[['name']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_summary_df = pd.DataFrame(train_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "val_encoded_summary_df = pd.DataFrame(val_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "test_encoded_summary_df = pd.DataFrame(test_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'name' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_summary_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_summary_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cab_type'] = train_df['cab_type'].str.strip()\n",
    "val_df['cab_type'] = val_df['cab_type'].str.strip()\n",
    "test_df['cab_type'] = test_df['cab_type'].str.strip()\n",
    "\n",
    "# Ensure there are no leading or trailing spaces in the 'cab_type' column\n",
    "train_df['cab_type'] = train_df['cab_type'].str.strip()\n",
    "val_df['cab_type'] = val_df['cab_type'].str.strip()\n",
    "test_df['cab_type'] = test_df['cab_type'].str.strip()\n",
    "\n",
    "# Create dummy variables for the 'cab_type' column\n",
    "train_df = pd.get_dummies(train_df, columns=['cab_type'], drop_first=True)\n",
    "val_df = pd.get_dummies(val_df, columns=['cab_type'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=['cab_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop encoded categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns_to_drop = ['source',\n",
    " 'destination',\n",
    " 'name']\n",
    "\n",
    "train_df = train_df.drop(columns = cat_columns_to_drop)\n",
    "val_df = val_df.drop(columns = cat_columns_to_drop)\n",
    "test_df = test_df.drop(columns = cat_columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and PCA\n",
    "#### First, let's standardize our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[['price']]\n",
    "y_val = val_df[['price']]\n",
    "y_test = test_df[['price']]\n",
    "\n",
    "X_train = train_df.drop('price', axis = 1)\n",
    "X_val = val_df.drop('price', axis = 1)\n",
    "X_test = test_df.drop('price', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaled DataFrames as Parquet files\n",
    "\n",
    "X_train_scaled_df.to_parquet(os.path.join(processed_data_folder, 'X_train_scaled.parquet'), index=False)\n",
    "X_val_scaled_df.to_parquet(os.path.join(processed_data_folder, 'X_val_scaled.parquet'), index=False)\n",
    "X_test_scaled_df.to_parquet(os.path.join(processed_data_folder, 'X_test_scaled.parquet'), index=False)\n",
    "\n",
    "# Save the target variables (if needed)\n",
    "y_train.to_parquet(os.path.join(processed_data_folder, 'y_train.parquet'), index=False)\n",
    "y_val.to_parquet(os.path.join(processed_data_folder, 'y_val.parquet'), index=False)\n",
    "y_test.to_parquet(os.path.join(processed_data_folder, 'y_test.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA, you can adjust n_components as needed (for example, n_components=0.95 for 95% variance)\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "\n",
    "X_train_scaled = X_train_scaled_df.to_numpy()\n",
    "X_val_scaled = X_val_scaled_df.to_numpy()\n",
    "X_test_scaled = X_test_scaled_df.to_numpy()\n",
    "\n",
    "# Fit PCA on the scaled training data\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Transform the validation and test sets using the same PCA\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Convert the PCA results back to DataFrames for easier handling\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_val_pca_df = pd.DataFrame(X_val_pca)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca)\n",
    "\n",
    "# Optional: Rename the columns for clarity\n",
    "X_train_pca_df.columns = [f'PC{i+1}' for i in range(X_train_pca_df.shape[1])]\n",
    "X_val_pca_df.columns = [f'PC{i+1}' for i in range(X_val_pca_df.shape[1])]\n",
    "X_test_pca_df.columns = [f'PC{i+1}' for i in range(X_test_pca_df.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 45)\n",
      "(20000, 45)\n",
      "(10000, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca_df.shape)\n",
    "print(X_val_pca_df.shape)\n",
    "print(X_test_pca_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA DataFrames as Parquet files\n",
    "train_pca_path = os.path.join(processed_data_folder, 'X_train_pca.parquet')\n",
    "val_pca_path = os.path.join(processed_data_folder, 'X_val_pca.parquet')\n",
    "test_pca_path = os.path.join(processed_data_folder, 'X_test_pca.parquet')\n",
    "\n",
    "X_train_pca_df.to_parquet(train_pca_path, index=False)\n",
    "X_val_pca_df.to_parquet(val_pca_path, index=False)\n",
    "X_test_pca_df.to_parquet(test_pca_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first modeling method we will use is linear regression. We will use ridge regression (L2) to vary the regularization strength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three models with varying regularization strengths\n",
    "ridge_model_1 = Ridge(alpha=0.001)  # low regularization\n",
    "ridge_model_2 = Ridge(alpha=0.01)  # medium regularization\n",
    "ridge_model_3 = Ridge(alpha=1) # high regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train each Ridge model\n",
    "ridge_model_1.fit(X_train_scaled, y_train)\n",
    "ridge_model_2.fit(X_train_scaled, y_train)\n",
    "ridge_model_3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training and validation datasets\n",
    "y_train_pred_1 = ridge_model_1.predict(X_train_scaled)\n",
    "y_val_pred_1 = ridge_model_1.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_2 = ridge_model_2.predict(X_train_scaled)\n",
    "y_val_pred_2 = ridge_model_2.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_3 = ridge_model_3.predict(X_train_scaled)\n",
    "y_val_pred_3 = ridge_model_3.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics (MSE and R-squared) for training and validation datasets\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train_scaled: 0\n",
      "NaN values in X_val_scaled: 0\n",
      "NaN values in y_train: price    0\n",
      "dtype: int64\n",
      "NaN values in y_val: price    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the training and validation sets\n",
    "print(\"NaN values in X_train_scaled:\", np.isnan(X_train_scaled).sum())\n",
    "print(\"NaN values in X_val_scaled:\", np.isnan(X_val_scaled).sum())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).sum())\n",
    "print(\"NaN values in y_val:\", np.isnan(y_val).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Ridge model 1\n",
    "train_mse_1, train_r2_1 = evaluate_model(y_train, y_train_pred_1)\n",
    "val_mse_1, val_r2_1 = evaluate_model(y_val, y_val_pred_1)\n",
    "\n",
    "# Evaluate Ridge model 2\n",
    "train_mse_2, train_r2_2 = evaluate_model(y_train, y_train_pred_2)\n",
    "val_mse_2, val_r2_2 = evaluate_model(y_val, y_val_pred_2)\n",
    "\n",
    "# Evaluate Ridge model 3\n",
    "train_mse_3, train_r2_3 = evaluate_model(y_train, y_train_pred_3)\n",
    "val_mse_3, val_r2_3 = evaluate_model(y_val, y_val_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (alpha=0.1) - Training MSE: 6868.4819, R2: 0.2146\n",
      "Validation MSE: 6475.0053, R2: 0.2055\n",
      "Model 2 (alpha=1.0) - Training MSE: 6868.4965, R2: 0.2146\n",
      "Validation MSE: 6475.1198, R2: 0.2055\n",
      "Model 3 (alpha=10.0) - Training MSE: 6868.8433, R2: 0.2145\n",
      "Validation MSE: 6475.6536, R2: 0.2054\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Model 1 (alpha=0.1) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_1, train_r2_1))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_1, val_r2_1))\n",
    "\n",
    "print(\"Model 2 (alpha=1.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_2, train_r2_2))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_2, val_r2_2))\n",
    "\n",
    "print(\"Model 3 (alpha=10.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_3, train_r2_3))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_3, val_r2_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.88054871e-01 -6.48325275e+00 -8.96070865e+00  1.59479198e+00\n",
      "   1.30806395e+00  1.40753263e-01  6.04357959e-02  1.88058422e+01\n",
      "  -4.63258217e+00 -2.22116946e-01 -1.15274108e-01  1.03061618e+01\n",
      "   8.25073696e-02 -1.22082874e+00  2.21943328e+01  6.55676712e-01\n",
      "  -1.18436423e+02  8.42498081e+01  3.31387514e+00 -1.20633913e+02\n",
      "   6.25660407e+01 -4.11222992e+02 -2.48571953e+00  8.69638276e+01\n",
      "  -2.01279114e+01 -2.19894965e+00 -8.92567905e-01  3.18794515e-01\n",
      "  -1.06505890e-01 -1.65180168e+00 -2.74156315e+02  3.29602016e+02\n",
      "  -4.87967910e-01 -5.03045270e-01 -1.77606906e+02  4.30379457e+00\n",
      "   5.76577664e+01  1.07437961e+02 -7.60960688e-02 -5.03901127e+00\n",
      "  -3.05633853e+01 -5.37219128e+01  4.36925197e+02 -5.30218049e-01\n",
      "  -8.01163085e-02  3.68394959e-01 -2.88799115e+00 -3.23628554e+00\n",
      "   1.96754770e-01  3.85922586e-01 -2.63877668e+00 -6.07111159e-01\n",
      "  -4.26911098e-02 -2.84148153e+00  5.52724588e-01 -1.65070858e-01\n",
      "   1.45600442e+01 -3.14517784e+00 -3.03899909e+00 -2.91868051e+00\n",
      "   2.00246856e-01  7.02903670e-01 -2.77064304e+00 -3.27745414e-01\n",
      "  -2.31377491e-01 -2.84937181e+00 -2.26122840e-01 -4.40873393e-01\n",
      "   1.49649582e+01 -3.18342283e+00 -2.64564513e+00 -1.13914412e-01\n",
      "  -1.22938285e+00  1.00813422e-01  2.64859849e+00 -3.47274832e+00\n",
      "  -2.01417921e+00 -4.07249281e+00  3.15249076e+01 -5.90927183e+00\n",
      "  -5.56861757e+00 -4.02492747e+00 -5.76506266e+00  4.24871020e+00]]\n",
      "[[-8.74430563e-01 -6.28242733e+00 -8.77355085e+00  1.59443527e+00\n",
      "   1.30786737e+00  1.57753195e-01  6.85191642e-02  1.87738030e+01\n",
      "  -4.63442784e+00 -2.15821502e-01 -1.18436287e-01  1.02983574e+01\n",
      "   5.71951955e-02 -1.19923211e+00  2.38282825e+01  6.51282025e-01\n",
      "  -9.84165467e+01  8.07143062e+01  3.10434878e+00 -1.17181009e+02\n",
      "   5.21510204e+01 -3.34029588e+02 -2.49685472e+00  8.28532789e+01\n",
      "  -2.01110099e+01 -2.27834741e+00 -8.91588416e-01  3.20112652e-01\n",
      "  -1.05487030e-01 -1.61367000e+00 -2.00625854e+01  4.27437500e+01\n",
      "  -5.96814159e-01 -5.13884604e-01 -1.46458234e+02  4.26070705e+00\n",
      "   5.30366319e+01  8.86222909e+01 -2.70846913e+00 -5.07849937e+00\n",
      "  -2.90570317e+01 -4.40320560e+01  3.69730592e+02 -5.24331476e-01\n",
      "  -4.60529913e-02  3.85943806e-01 -2.88795936e+00 -3.23662684e+00\n",
      "   1.96531084e-01  3.86076322e-01 -2.63851125e+00 -6.07566811e-01\n",
      "  -4.27391643e-02 -2.84153784e+00  5.52923597e-01 -1.64616646e-01\n",
      "   1.45604080e+01 -3.14547820e+00 -3.03877233e+00 -2.91847753e+00\n",
      "   2.00580495e-01  7.02644248e-01 -2.77058284e+00 -3.28189914e-01\n",
      "  -2.30805416e-01 -2.84946023e+00 -2.26311274e-01 -4.40965473e-01\n",
      "   1.49649496e+01 -3.18372245e+00 -2.64543891e+00 -1.14100177e-01\n",
      "  -1.22948811e+00  1.01035430e-01  2.64876134e+00 -3.47288031e+00\n",
      "  -2.01425748e+00 -4.07268618e+00  3.15248392e+01 -5.90917621e+00\n",
      "  -5.56888955e+00 -4.02502980e+00 -5.76459430e+00  4.24876793e+00]]\n",
      "[[-8.29221837e-01 -5.54903176e+00 -7.99033705e+00  1.59567471e+00\n",
      "   1.30747218e+00  3.38080825e-01  4.91820356e-02  1.86275073e+01\n",
      "  -4.72518824e+00 -1.81965286e-01 -1.09957667e-01  1.01765027e+01\n",
      "  -1.58750013e-01 -1.02640941e+00  1.14255513e+01  5.99216593e-01\n",
      "  -9.87241611e+00  3.00529292e+01  2.42703819e+00 -4.79386814e+01\n",
      "   8.61912665e+00  7.03514048e+00 -1.74728062e+00  1.98432022e+01\n",
      "  -1.98143659e+01 -2.54118304e+00 -8.45019358e-01  3.06031133e-01\n",
      "  -1.08232971e-01 -1.35865593e+00 -1.43689417e+01 -1.36610069e+01\n",
      "  -1.06663941e+00 -1.20734288e+00 -2.26925448e+01  4.18252572e+00\n",
      "   6.40434833e+00  5.60834995e+00 -1.43627844e+01 -5.83099703e+00\n",
      "   1.53540173e+00 -3.88600850e+00  4.06514401e+01 -4.72711430e-01\n",
      "   2.08316086e-02  4.53649304e-01 -2.88848225e+00 -3.23649006e+00\n",
      "   1.95889227e-01  3.85168200e-01 -2.63889594e+00 -6.09070634e-01\n",
      "  -4.37604686e-02 -2.84152172e+00  5.54790834e-01 -1.62236592e-01\n",
      "   1.45619902e+01 -3.14646949e+00 -3.03739732e+00 -2.91718437e+00\n",
      "   2.01311483e-01  7.01523127e-01 -2.77204650e+00 -3.29989300e-01\n",
      "  -2.27708124e-01 -2.84896626e+00 -2.26419834e-01 -4.41943061e-01\n",
      "   1.49662462e+01 -3.18651736e+00 -2.64449465e+00 -1.14784532e-01\n",
      "  -1.23148106e+00  1.01604952e-01  2.64934911e+00 -3.47395257e+00\n",
      "  -2.01339872e+00 -4.07366012e+00  3.15247409e+01 -5.90844597e+00\n",
      "  -5.56891162e+00 -4.02567882e+00 -5.76281235e+00  4.24984220e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Investigating the similar outputs\n",
    "print(ridge_model_1.coef_)\n",
    "print(ridge_model_2.coef_)\n",
    "print(ridge_model_3.coef_)\n",
    "#Based on the similar coefficients for the Ridge models with different alpha values it seems like Ridge regularization is not playing a major role in altering the model's predictions. This might be because the features are already well scaled. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 (alpha=100.0) - Training MSE: 6869.4575, R2: 0.2145\n",
      "Model 5 (alpha=1000.0) - Training MSE: 6870.2419, R2: 0.2144\n"
     ]
    }
   ],
   "source": [
    "#Continuation of ridge regression exploration\n",
    "#Testing with higher alpha values (alpha=100)\n",
    "ridge_model_4 = Ridge(alpha=100) \n",
    "ridge_model_4.fit(X_train_scaled, y_train)\n",
    "y_train_pred_4 = ridge_model_4.predict(X_train_scaled)\n",
    "y_val_pred_4 = ridge_model_4.predict(X_val_scaled)\n",
    "# Evaluate Ridge model 3\n",
    "train_mse_4, train_r2_4 = evaluate_model(y_train, y_train_pred_4)\n",
    "print(\"Model 4 (alpha=100.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_4, train_r2_4))\n",
    "\n",
    "\n",
    "#Testing with higher alpha values (alpha=1000)\n",
    "ridge_model_5 = Ridge(alpha=1000) \n",
    "ridge_model_5.fit(X_train_scaled, y_train)\n",
    "y_train_pred_5 = ridge_model_5.predict(X_train_scaled)\n",
    "y_val_pred_5 = ridge_model_5.predict(X_val_scaled)\n",
    "# Evaluate Ridge model 3\n",
    "train_mse_5, train_r2_5 = evaluate_model(y_train, y_train_pred_5)\n",
    "print(\"Model 5 (alpha=1000.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_5, train_r2_5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+08, tolerance: 6.121e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Model 1 (alpha=0.001) - Training MSE: 6869.2573, R2: 0.2145\n",
      "Validation MSE: 6475.0757, R2: 0.2055\n",
      "Lasso Model 2 (alpha=0.01) - Training MSE: 6869.7284, R2: 0.2144\n",
      "Validation MSE: 6474.2080, R2: 0.2056\n",
      "Lasso Model 3 (alpha=1.0) - Training MSE: 6887.8521, R2: 0.2124\n",
      "Validation MSE: 6476.0189, R2: 0.2054\n"
     ]
    }
   ],
   "source": [
    "#3 different Lasso regularization terms\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define three models with varying regularization strengths for Lasso\n",
    "lasso_model_1 = Lasso(alpha=0.001)  # low regularization\n",
    "lasso_model_2 = Lasso(alpha=0.01)   # medium regularization\n",
    "lasso_model_3 = Lasso(alpha=1)      # high regularization\n",
    "\n",
    "# Train each Lasso model\n",
    "lasso_model_1.fit(X_train_scaled, y_train)\n",
    "lasso_model_2.fit(X_train_scaled, y_train)\n",
    "lasso_model_3.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the training and validation datasets\n",
    "y_train_pred_lasso_1 = lasso_model_1.predict(X_train_scaled)\n",
    "y_val_pred_lasso_1 = lasso_model_1.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_lasso_2 = lasso_model_2.predict(X_train_scaled)\n",
    "y_val_pred_lasso_2 = lasso_model_2.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_lasso_3 = lasso_model_3.predict(X_train_scaled)\n",
    "y_val_pred_lasso_3 = lasso_model_3.predict(X_val_scaled)\n",
    "\n",
    "# Calculate evaluation metrics (MSE and R-squared) for training and validation datasets\n",
    "train_mse_lasso_1, train_r2_lasso_1 = evaluate_model(y_train, y_train_pred_lasso_1)\n",
    "val_mse_lasso_1, val_r2_lasso_1 = evaluate_model(y_val, y_val_pred_lasso_1)\n",
    "\n",
    "train_mse_lasso_2, train_r2_lasso_2 = evaluate_model(y_train, y_train_pred_lasso_2)\n",
    "val_mse_lasso_2, val_r2_lasso_2 = evaluate_model(y_val, y_val_pred_lasso_2)\n",
    "\n",
    "train_mse_lasso_3, train_r2_lasso_3 = evaluate_model(y_train, y_train_pred_lasso_3)\n",
    "val_mse_lasso_3, val_r2_lasso_3 = evaluate_model(y_val, y_val_pred_lasso_3)\n",
    "\n",
    "# Print results\n",
    "print(\"Lasso Model 1 (alpha=0.001) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_lasso_1, train_r2_lasso_1))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_lasso_1, val_r2_lasso_1))\n",
    "\n",
    "print(\"Lasso Model 2 (alpha=0.01) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_lasso_2, train_r2_lasso_2))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_lasso_2, val_r2_lasso_2))\n",
    "\n",
    "print(\"Lasso Model 3 (alpha=1.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_lasso_3, train_r2_lasso_3))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_lasso_3, val_r2_lasso_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Model - Training MSE: 2.8405, R2: 0.9997\n",
      "Validation MSE: 59460830145836358828032.0000, R2: -7295900558419439616.0000\n"
     ]
    }
   ],
   "source": [
    "#Generating polynomial features with NO regularization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Generate polynomial features\n",
    "poly = PolynomialFeatures(degree=2)  # Adjust the degree as needed\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_val_poly = poly.transform(X_val_scaled)\n",
    "\n",
    "# Step 2: Fit the Linear Regression model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_train_pred_poly = poly_model.predict(X_train_poly)\n",
    "y_val_pred_poly = poly_model.predict(X_val_poly)\n",
    "\n",
    "# Step 4: Calculate evaluation metrics (MSE and R-squared)\n",
    "train_mse_poly, train_r2_poly = evaluate_model(y_train, y_train_pred_poly)\n",
    "val_mse_poly, val_r2_poly = evaluate_model(y_val, y_val_pred_poly)\n",
    "\n",
    "# Print results\n",
    "print(\"Polynomial Regression Model - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_poly, train_r2_poly))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_poly, val_r2_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial feature with lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_val_poly = poly.transform(X_val_scaled)\n",
    "\n",
    "# Step 2: Fit the Lasso regression model\n",
    "lasso_model = Lasso(alpha=1.0)  # Adjust alpha for different regularization strengths\n",
    "lasso_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_train_pred_lasso = lasso_model.predict(X_train_poly)\n",
    "y_val_pred_lasso = lasso_model.predict(X_val_poly)\n",
    "\n",
    "# Step 4: Calculate evaluation metrics (MSE and R-squared)\n",
    "train_mse_lasso, train_r2_lasso = evaluate_model(y_train, y_train_pred_lasso)\n",
    "val_mse_lasso, val_r2_lasso = evaluate_model(y_val, y_val_pred_lasso)\n",
    "\n",
    "# Print results\n",
    "print(\"Lasso Regression Model - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_lasso, train_r2_lasso))\n",
    "print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_lasso, val_r2_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model (alpha=1.0) - Training MSE: 2.8320, R2: 0.9997\n",
      "Validation MSE: 9.7312, R2: 0.9988\n",
      "Ridge Regression Model (alpha=10.0) - Training MSE: 2.8392, R2: 0.9997\n",
      "Validation MSE: 9.6947, R2: 0.9988\n",
      "Ridge Regression Model (alpha=100.0) - Training MSE: 2.8588, R2: 0.9997\n",
      "Validation MSE: 9.4152, R2: 0.9988\n"
     ]
    }
   ],
   "source": [
    "#Polynomial feature with 3 different ridge regressions \n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Step 1: Generate polynomial features\n",
    "poly = PolynomialFeatures(degree=2)  # Adjust the degree as needed\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_val_poly = poly.transform(X_val_scaled)\n",
    "\n",
    "# Define the alpha values you want to test\n",
    "alpha_values = [1.0, 10.0, 100.0]  # You can adjust these values as needed\n",
    "\n",
    "# Loop through the different alpha values\n",
    "for alpha in alpha_values:\n",
    "    # Step 2: Fit the Ridge regression model with the current alpha\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Step 3: Make predictions\n",
    "    y_train_pred_ridge = ridge_model.predict(X_train_poly)\n",
    "    y_val_pred_ridge = ridge_model.predict(X_val_poly)\n",
    "\n",
    "    # Step 4: Calculate evaluation metrics (MSE and R-squared)\n",
    "    train_mse_ridge, train_r2_ridge = evaluate_model(y_train, y_train_pred_ridge)\n",
    "    val_mse_ridge, val_r2_ridge = evaluate_model(y_val, y_val_pred_ridge)\n",
    "\n",
    "    # Print results for the current alpha\n",
    "    print(\"Ridge Regression Model (alpha={}) - Training MSE: {:.4f}, R2: {:.4f}\".format(alpha, train_mse_ridge, train_r2_ridge))\n",
    "    print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_ridge, val_r2_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
