{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Notebook: Model training, hyperparameter tuning, and model evaluation\n",
    "The goal of this week's assignment is to use a third modeling method with 3 different hyperparameter settings of the method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "processed_data_folder = os.path.join(data_folder, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data path\n",
    "X_train_scaled_path = os.path.join(processed_data_folder, 'X_train_scaled.parquet')\n",
    "X_val_scaled_path = os.path.join(processed_data_folder, 'X_val_scaled.parquet')\n",
    "X_test_scaled_path = os.path.join(processed_data_folder, 'X_test_scaled.parquet')\n",
    "\n",
    "train_pca_path = os.path.join(processed_data_folder, 'X_train_pca.parquet')\n",
    "val_pca_path = os.path.join(processed_data_folder, 'X_val_pca.parquet')\n",
    "test_pca_path = os.path.join(processed_data_folder, 'X_test_pca.parquet')\n",
    "# Y data path\n",
    "y_train_path = os.path.join(processed_data_folder, 'y_train.parquet')\n",
    "y_val_path = os.path.join(processed_data_folder, 'y_val.parquet')\n",
    "y_test_path = os.path.join(processed_data_folder, 'y_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the parquet files as dataframes\n",
    "X_train_scaled = pd.read_parquet(X_train_scaled_path)\n",
    "X_val_scaled = pd.read_parquet(X_val_scaled_path)\n",
    "X_test_scaled = pd.read_parquet(X_test_scaled_path)\n",
    "\n",
    "y_train = pd.read_parquet(y_train_path)\n",
    "y_val = pd.read_parquet(y_val_path)\n",
    "y_test = pd.read_parquet(y_test_path)\n",
    "\n",
    "X_train_pca = pd.read_parquet(train_pca_path)\n",
    "X_val_pca = pd.read_parquet(val_pca_path)\n",
    "X_test_pca = pd.read_parquet(test_pca_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for Modeling\n",
    "#### Ravel y into numpy array\n",
    "Sklearn random forest requires y to be an 1D array, so we need to ravel the panda dataframe to a 1D numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_val = y_val.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mse = rmse**2\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "#### Random Forest\n",
    "Random Forest can be computationally intensive, making cross-validation difficult when tuning hyperparameters. To streamline the process of experimenting with multiple hyperparameters, we created a function that automates the training and evaluation steps on the validation set, helping us identify the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_rf(X_train, X_val, y_train, y_val, param_combinations, lowest_rmse = float('inf')):\n",
    "    for params in param_combinations:\n",
    "    # Initialize the model with the current parameters\n",
    "        rf_model = RandomForestRegressor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        max_features=params['max_features'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "        rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation data\n",
    "        y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "        rmse = root_mean_squared_error(y_val, y_val_pred)\n",
    "    \n",
    "    # Check if this is the best model so far\n",
    "        if rmse < lowest_rmse:\n",
    "            lowest_rmse = rmse\n",
    "            best_model = rf_model\n",
    "            best_params = params\n",
    "            print(\"Best Parameters:\", best_params)\n",
    "            print(\"Lowest RMSE on validation set:\", lowest_rmse)\n",
    "    return best_model, best_params, lowest_rmse\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning `n_estimators`\n",
    "`n_estimators` refers number of decision trees in the random forest. We first want to experiment how that affect the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'log2'}\n",
      "Lowest RMSE on validation set: 63.2406685389967\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'log2'}\n",
      "Lowest RMSE on validation set: 60.647192316432616\n"
     ]
    }
   ],
   "source": [
    "param_combinations = [\n",
    "    {'n_estimators': 50, 'max_depth': 10, 'max_features':'log2'},\n",
    "    {'n_estimators': 100, 'max_depth': 10, 'max_features': 'log2'},\n",
    "    {'n_estimators': 150, 'max_depth': 10, 'max_features': 'log2'}\n",
    "]\n",
    "\n",
    "best_model, best_params, lowest_rmse = best_rf(X_train_scaled, X_val_scaled, y_train, y_val, param_combinations,lowest_rmse = float('inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning `max_depth`\n",
    "`max_depth` controls the maximum depth of each decision tree in the random forest. We will experiment with this parameter to understand its impact on model performance and find an optimal value that balances complexity and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'log2'}\n",
      "Lowest RMSE on validation set: 41.15554705419018\n"
     ]
    }
   ],
   "source": [
    "param_combinations = [\n",
    "    {'n_estimators': 100, 'max_depth': 5, 'max_features': 'log2'},\n",
    "    {'n_estimators': 100, 'max_depth': 10, 'max_features': 'log2'},\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'max_features': 'log2'}\n",
    "]\n",
    "best_model, best_params, lowest_rmse = best_rf(X_train_scaled, X_val_scaled, y_train, y_val, param_combinations, lowest_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning `max_features`\n",
    "`max_features` determines the maximum number of features considered when splitting a node in each decision tree. We will experiment with different values to see how this parameter affects model performance, aiming to find a balance between diversity in the trees and overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': None}\n",
      "Lowest RMSE on validation set: 1.739659226065485\n"
     ]
    }
   ],
   "source": [
    "param_combinations = [\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'max_features': None},\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'max_features': 'log2'},\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt'}\n",
    "]\n",
    "best_model, best_params, lowest_rmse = best_rf(X_train_scaled, X_val_scaled, y_train, y_val, param_combinations, lowest_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Best Model\n",
    "While the model does perform a lot better, the performance metrics shows that the model is overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Model - Training Metrics:\n",
      "MSE: 1.7703, RMSE: 1.3305, R²: 0.9998\n",
      "\n",
      "Decision Tree Regression Model - Validation Metrics:\n",
      "MSE: 3.0264, RMSE: 1.7397, R²: 0.9996\n",
      "\n",
      "Decision Tree Regression Model - Validation Metrics:\n",
      "MSE: 3.0264, RMSE: 1.7397, R²: 0.9996\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_tree = best_model.predict(X_train_scaled)\n",
    "y_test_pred_tree = best_model.predict(X_test_scaled)\n",
    "y_val_pred_tree = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "train_mse_tree, train_rmse_tree, train_r2_tree = evaluate_model(y_train, y_train_pred_tree)\n",
    "val_mse_tree, val_rmse_tree, val_r2_tree = evaluate_model(y_val, y_val_pred_tree)\n",
    "test_mse_tree, test_rmse_tree, test_r2_tree = evaluate_model(y_test, y_test_pred_tree)\n",
    "\n",
    "# Print training metrics\n",
    "print(\"Decision Tree Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_tree:.4f}, RMSE: {train_rmse_tree:.4f}, R²: {train_r2_tree:.4f}\")\n",
    "\n",
    "# Print validation metrics\n",
    "print(\"\\nDecision Tree Regression Model - Validation Metrics:\") \n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")\n",
    "\n",
    "# Print testing metrics\n",
    "print(\"\\nDecision Tree Regression Model - Validation Metrics:\") \n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment if more estimators and `max_features` = n_features will lead to better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 150, 'max_depth': 15, 'max_features': None}\n",
      "Lowest RMSE on validation set: 1.7372547398224727\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 15, 'max_features': None}\n",
      "Lowest RMSE on validation set: 1.73583835395773\n"
     ]
    }
   ],
   "source": [
    "param_combinations = [\n",
    "    {'n_estimators': 150, 'max_depth': 15, 'max_features': None},\n",
    "    {'n_estimators': 200, 'max_depth': 15, 'max_features': None},\n",
    "    {'n_estimators': 250, 'max_depth': 15, 'max_features': None}\n",
    "]\n",
    "best_model, best_params, lowest_rmse = best_rf(X_train_scaled, X_val_scaled, y_train, y_val, param_combinations, lowest_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the model shows slightly improved performance but still overfits the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Model - Training Metrics:\n",
      "MSE: 1.7664, RMSE: 1.3290, R²: 0.9998\n",
      "\n",
      "Decision Tree Regression Model - Validation Metrics:\n",
      "MSE: 3.0131, RMSE: 1.7358, R²: 0.9996\n",
      "\n",
      "Decision Tree Regression Model - Validation Metrics:\n",
      "MSE: 3.0131, RMSE: 1.7358, R²: 0.9996\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_tree = best_model.predict(X_train_scaled)\n",
    "y_test_pred_tree = best_model.predict(X_test_scaled)\n",
    "y_val_pred_tree = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "train_mse_tree, train_rmse_tree, train_r2_tree = evaluate_model(y_train, y_train_pred_tree)\n",
    "val_mse_tree, val_rmse_tree, val_r2_tree = evaluate_model(y_val, y_val_pred_tree)\n",
    "test_mse_tree, test_rmse_tree, test_r2_tree = evaluate_model(y_test, y_test_pred_tree)\n",
    "\n",
    "# Print training metrics\n",
    "print(\"Decision Tree Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_tree:.4f}, RMSE: {train_rmse_tree:.4f}, R²: {train_r2_tree:.4f}\")\n",
    "\n",
    "# Print validation metrics\n",
    "print(\"\\nDecision Tree Regression Model - Validation Metrics:\") \n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")\n",
    "\n",
    "# Print testing metrics\n",
    "print(\"\\nDecision Tree Regression Model - Validation Metrics:\") \n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addressing Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': None}\n",
      "Lowest RMSE on validation set: 1.9596762830031542\n",
      "Best Parameters: {'n_estimators': 150, 'max_depth': 10, 'max_features': None}\n",
      "Lowest RMSE on validation set: 1.9571073467668085\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10, 'max_features': None}\n",
      "Lowest RMSE on validation set: 1.9556063496243887\n"
     ]
    }
   ],
   "source": [
    "param_combinations = [\n",
    "    {'n_estimators': 100, 'max_depth': 10, 'max_features': None},\n",
    "    {'n_estimators': 150, 'max_depth': 10, 'max_features': None},\n",
    "    {'n_estimators': 200, 'max_depth': 10, 'max_features': None},\n",
    "]\n",
    "best_model, best_params, lowest_rmse = best_rf(X_train_scaled, X_val_scaled, y_train, y_val, param_combinations, lowest_rmse= float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Model - Training Metrics:\n",
      "MSE: 3.3915, RMSE: 1.8416, R²: 0.9996\n",
      "\n",
      "Decision Tree Regression Model - Validation Metrics:\n",
      "MSE: 3.8244, RMSE: 1.9556, R²: 0.9995\n",
      "\n",
      "Decision Tree Regression Model - Validation Metrics:\n",
      "MSE: 3.8244, RMSE: 1.9556, R²: 0.9995\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_tree = best_model.predict(X_train_scaled)\n",
    "y_test_pred_tree = best_model.predict(X_test_scaled)\n",
    "y_val_pred_tree = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "train_mse_tree, train_rmse_tree, train_r2_tree = evaluate_model(y_train, y_train_pred_tree)\n",
    "val_mse_tree, val_rmse_tree, val_r2_tree = evaluate_model(y_val, y_val_pred_tree)\n",
    "test_mse_tree, test_rmse_tree, test_r2_tree = evaluate_model(y_test, y_test_pred_tree)\n",
    "\n",
    "# Print training metrics\n",
    "print(\"Decision Tree Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_tree:.4f}, RMSE: {train_rmse_tree:.4f}, R²: {train_r2_tree:.4f}\")\n",
    "\n",
    "# Print validation metrics\n",
    "print(\"\\nDecision Tree Regression Model - Validation Metrics:\") \n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")\n",
    "\n",
    "# Print testing metrics\n",
    "print(\"\\nDecision Tree Regression Model - Validation Metrics:\") \n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
