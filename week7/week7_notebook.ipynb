{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Notebook: Model training, hyperparameter tuning, and model evaluation\n",
    "The goal of this week's assignment is to use one modeling method with 3 different hyperparameter settings of the method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "processed_data_folder = os.path.join(data_folder, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA DataFrames as Parquet files\n",
    "X_train_scaled_path = os.path.join(processed_data_folder, 'X_train_scaled.parquet')\n",
    "X_val_scaled_path = os.path.join(processed_data_folder, 'X_val_scaled.parquet')\n",
    "X_test_scaled_path = os.path.join(processed_data_folder, 'X_test_scaled.parquet')\n",
    "\n",
    "# Paths for the target variables\n",
    "y_train_path = os.path.join(processed_data_folder, 'y_train.parquet')\n",
    "y_val_path = os.path.join(processed_data_folder, 'y_val.parquet')\n",
    "y_test_path = os.path.join(processed_data_folder, 'y_test.parquet')\n",
    "\n",
    "train_pca_path = os.path.join(processed_data_folder, 'X_train_pca.parquet')\n",
    "val_pca_path = os.path.join(processed_data_folder, 'X_val_pca.parquet')\n",
    "test_pca_path = os.path.join(processed_data_folder, 'X_test_pca.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\holly\\\\OneDrive\\\\Documents\\\\GitHub\\\\ADAN8888.01_Fall_24_Applied_Analytics_Project\\\\data\\\\processed\\\\X_train_scaled.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(X_train_scaled_path)\n\u001b[0;32m      2\u001b[0m X_val_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(X_val_scaled_path)\n\u001b[0;32m      3\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(X_test_scaled_path)\n",
      "File \u001b[1;32mc:\\Users\\holly\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    671\u001b[0m     path,\n\u001b[0;32m    672\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    673\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    674\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    675\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    676\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    677\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    679\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holly\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:265\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    263\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    266\u001b[0m     path,\n\u001b[0;32m    267\u001b[0m     filesystem,\n\u001b[0;32m    268\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    269\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    270\u001b[0m )\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    273\u001b[0m         path_or_handle,\n\u001b[0;32m    274\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    278\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\holly\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:139\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    129\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m    140\u001b[0m         path_or_handle, mode, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\holly\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\holly\\\\OneDrive\\\\Documents\\\\GitHub\\\\ADAN8888.01_Fall_24_Applied_Analytics_Project\\\\data\\\\processed\\\\X_train_scaled.parquet'"
     ]
    }
   ],
   "source": [
    "X_train_scaled = pd.read_parquet(X_train_scaled_path)\n",
    "X_val_scaled = pd.read_parquet(X_val_scaled_path)\n",
    "X_test_scaled = pd.read_parquet(X_test_scaled_path)\n",
    "\n",
    "# Reading the target variables\n",
    "y_train = pd.read_parquet(y_train_path)\n",
    "y_val = pd.read_parquet(y_val_path)\n",
    "y_test = pd.read_parquet(y_test_path)\n",
    "\n",
    "X_train_pca = pd.read_parquet(train_pca_path)\n",
    "X_val_pca = pd.read_parquet(val_pca_path)\n",
    "X_test_pca = pd.read_parquet(test_pca_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mse = rmse**2\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = LinearRegression()\n",
    "\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "ols_predictions = ols.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "ols_train_predictions = ols.predict(X_train_scaled)\n",
    "ols_predictions = ols.predict(X_test_scaled)\n",
    "\n",
    "ols_train_mse, ols_train_rmse, ols_train_r2 = evaluate_model(y_train, ols_train_predictions)\n",
    "ols_mse, ols_rmse, ols_r2 = evaluate_model(y_test, ols_predictions)\n",
    "\n",
    "# Print the metrics for training and validation sets\n",
    "print(\"OLS Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {ols_train_mse:.4f}, RMSE: {ols_train_rmse:.4f}, R²: {ols_train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nOLS Regression Model - Validation Metrics:\")\n",
    "print(f\"MSE: {ols_mse:.4f}, RMSE: {ols_rmse:.4f}, R²: {ols_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_pca = LinearRegression()\n",
    "\n",
    "ols_pca.fit(X_train_pca, y_train)\n",
    "ols_pca_train_predictions = ols_pca.predict(X_train_pca)\n",
    "ols_pca_predictions = ols_pca.predict(X_test_pca)\n",
    "\n",
    "ols_pca_train_mse, ols_pca_train_rmse, ols_pca_train_r2 = evaluate_model(y_train, ols_pca_train_predictions)\n",
    "ols_pca_mse, ols_pca_rmse, ols_pca_r2 = evaluate_model(y_test, ols_pca_predictions)\n",
    "\n",
    "\n",
    "print(\"OLS PCA Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {ols_pca_train_mse:.4f}, RMSE: {ols_pca_train_rmse:.4f}, R²: {ols_pca_train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nOLS PCA Regression Model - Validation Metrics:\")\n",
    "print(f\"MSE: {ols_pca_mse:.4f}, RMSE: {ols_pca_rmse:.4f}, R²: {ols_pca_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "#### L1\n",
    "Lasso is harder to converge, and it takes very long for lasso to cross validation and grid search. Therefore, the following cell takes very long to run and a lot of values of alpha fails to converge with limited iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alphas = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}  \n",
    "\n",
    "lasso = Lasso()\n",
    "lasso_cv = GridSearchCV(lasso, param_grid=lasso_alphas, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_lasso_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Lasso: {best_lasso_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best = Lasso(alpha=0.1)\n",
    "lasso_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred_lasso = lasso_best.predict(X_train_scaled)\n",
    "y_val_pred_lasso = lasso_best.predict(X_val_scaled)\n",
    "\n",
    "train_mse_lasso, train_rmse_lasso, train_r2_lasso = evaluate_model(y_train, y_train_pred_lasso)\n",
    "val_mse_lasso, val_rmse_lasso, val_r2_lasso = evaluate_model(y_val, y_val_pred_lasso) \n",
    "\n",
    "print(\"Lasso Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_lasso:.4f}, RMSE: {train_rmse_lasso:.4f}, R²: {train_r2_lasso:.4f}\")\n",
    "\n",
    "# Print the results for the validation dataset\n",
    "print(\"\\nLasso Regression Model - Validation Metrics:\")\n",
    "print(f\"MSE: {val_mse_lasso:.4f}, RMSE: {val_rmse_lasso:.4f}, R²: {val_r2_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge_alphas = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}  # Define alpha range\n",
    "ridge_cv = GridSearchCV(ridge, param_grid=ridge_alphas, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "best_ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Ridge: {best_ridge_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_best = Ridge(alpha=best_ridge_alpha)\n",
    "ridge_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred_ridge = ridge_best.predict(X_train_scaled)\n",
    "y_val_pred_ridge = ridge_best.predict(X_val_scaled) \n",
    "\n",
    "train_mse_ridge, train_rmse_ridge, train_r2_ridge = evaluate_model(y_train, y_train_pred_ridge)\n",
    "val_mse_ridge, val_rmse_ridge, val_r2_ridge = evaluate_model(y_val, y_val_pred_ridge) \n",
    "\n",
    "print(\"Ridge Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_ridge:.4f}, RMSE: {train_rmse_ridge:.4f}, R²: {train_r2_ridge:.4f}\")\n",
    "\n",
    "# Print the results for the validation dataset\n",
    "print(\"\\nRidge Regression Model - Validation Metrics:\")\n",
    "print(f\"MSE: {val_mse_ridge:.4f}, RMSE: {val_rmse_ridge:.4f}, R²: {val_r2_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with polynomial terms\n",
    "We commented out this part to save memories when running on JupyterHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly = PolynomialFeatures(degree=2) \n",
    "# X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "# X_val_poly = poly.transform(X_val_scaled)\n",
    "\n",
    "# poly_model = LinearRegression()\n",
    "# poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# y_train_pred_poly = poly_model.predict(X_train_poly)\n",
    "# y_val_pred_poly = poly_model.predict(X_val_poly)\n",
    "\n",
    "# train_mse_poly, train_rmse_poly, train_r2_poly = evaluate_model(y_train, y_train_pred_poly)\n",
    "# val_mse_poly, val_rmse_poly, val_r2_poly = evaluate_model(y_val, y_val_pred_poly) \n",
    "\n",
    "# # Print results\n",
    "# print(\"Polynomial Regression Model - Training Metrics:\")\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}\".format(train_mse_poly, train_rmse_poly, train_r2_poly))\n",
    "\n",
    "# print(\"\\nPolynomial Regression Model - Validation Metrics:\")\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}\".format(val_mse_poly, val_rmse_poly, val_r2_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge_poly_alphas = {'alpha': [0.01, 0.1, 1]} \n",
    "\n",
    "# ridge = Ridge()\n",
    "\n",
    "# ridge_cv = GridSearchCV(ridge, param_grid = ridge_poly_alphas, cv = 5, scoring='neg_mean_squared_error')\n",
    "# ridge_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "# best_ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "# print(f\"Best alpha for Ridge: {best_ridge_alpha}\")\n",
    "\n",
    "# ridge_best = Ridge(alpha=best_ridge_alpha)\n",
    "# ridge_best.fit(X_train_poly, y_train)\n",
    "\n",
    "# y_train_pred_ridge = ridge_best.predict(X_train_poly)\n",
    "# y_val_pred_ridge = ridge_best.predict(X_val_poly)\n",
    "\n",
    "# train_mse_ridge, train_rmse_ridge, train_r2_ridge = evaluate_model(y_train, y_train_pred_ridge)\n",
    "# val_mse_ridge, val_rmse_ridge, val_r2_ridge = evaluate_model(y_val, y_val_pred_ridge)\n",
    "\n",
    "# print(\"Ridge Regression Model (Best alpha={}) - Training Metrics:\".format(best_ridge_alpha))\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}\".format(train_mse_ridge, train_rmse_ridge, train_r2_ridge))\n",
    "# print(\"\\nValidation Metrics:\")\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}\".format(val_mse_ridge, val_rmse_ridge, val_r2_ridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
