{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Notebook: Data Centric AI\n",
    "The goal of this week's assignment is to apply data-centric AI principles to the modeling project. Using the final selected model, iterate over the data to improve the prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "processed_data_folder = os.path.join(data_folder, \"processed\")\n",
    "\n",
    "raw_data_file = os.path.join(raw_data_folder, 'rawSampledData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'timestamp', 'hour', 'day', 'month', 'timezone', 'source',\n",
      "       'destination', 'cab_type', 'product_id', 'name', 'price', 'distance',\n",
      "       'surge_multiplier', 'latitude', 'longitude', 'temperature',\n",
      "       'apparentTemperature', 'short_summary', 'long_summary',\n",
      "       'precipIntensity', 'precipProbability', 'humidity', 'windSpeed',\n",
      "       'windGust', 'windGustTime', 'visibility', 'temperatureHigh',\n",
      "       'temperatureHighTime', 'temperatureLow', 'temperatureLowTime',\n",
      "       'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
      "       'apparentTemperatureLow', 'apparentTemperatureLowTime', 'icon',\n",
      "       'dewPoint', 'pressure', 'windBearing', 'cloudCover', 'uvIndex',\n",
      "       'visibility.1', 'ozone', 'sunriseTime', 'sunsetTime', 'moonPhase',\n",
      "       'precipIntensityMax', 'uvIndexTime', 'temperatureMin',\n",
      "       'temperatureMinTime', 'temperatureMax', 'temperatureMaxTime',\n",
      "       'apparentTemperatureMin', 'apparentTemperatureMinTime',\n",
      "       'apparentTemperatureMax', 'apparentTemperatureMaxTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe.\n",
    "df = pd.read_csv(raw_data_file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training, testing, and validation sets\n",
    "- training set is 70% of the dataframe\n",
    "- validation set is 20% of the dataframe\n",
    "- test set is 10% of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df):\n",
    "    # Shuffle the dataset and calculate the size of validation and test sets\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123)\n",
    "\n",
    "    val_size = int(len(df) * 0.2)\n",
    "    test_size = int(len(df) * 0.1)\n",
    "\n",
    "    # Select rows based on the val_size and test_size to store as train set, val set, and test set\n",
    "    train_df = df.iloc[val_size + test_size:]\n",
    "    val_df = df.iloc[:val_size]\n",
    "    test_df = df.iloc[val_size:val_size + test_size]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new variables\n",
    "#### Weather-related Variable\n",
    "In week 5, `icon`, `short_summary`, and `long_summary`, were combined into one variable to reduce redundancy and dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes of icon:\n",
      "[' partly-cloudy-day ' ' rain ' ' cloudy ' ' clear-night ' ' clear-day '\n",
      " ' partly-cloudy-night ' ' fog ']\n",
      "\n",
      "Unique classes of short_summary:\n",
      "[' Mostly Cloudy ' ' Light Rain ' ' Overcast ' ' Clear ' ' Partly Cloudy '\n",
      " ' Rain ' ' Foggy ' ' Drizzle ' ' Possible Drizzle ']\n",
      "\n",
      "Unique classes of long_summary:\n",
      "[' Partly cloudy throughout the day. ' ' Light rain until evening. '\n",
      " ' Mostly cloudy throughout the day. '\n",
      " ' Rain until morning, starting again in the evening. '\n",
      " ' Light rain in the morning. ' ' Overcast throughout the day. '\n",
      " ' Foggy in the morning. ' ' Light rain in the morning and overnight. '\n",
      " ' Rain throughout the day. ' ' Possible drizzle in the morning. '\n",
      " ' Rain in the morning and afternoon. ']\n"
     ]
    }
   ],
   "source": [
    "print('Unique classes of icon:')\n",
    "print(df['icon'].unique())\n",
    "print('')\n",
    "print('Unique classes of short_summary:')\n",
    "print(df['short_summary'].unique())\n",
    "print('')\n",
    "print('Unique classes of long_summary:')\n",
    "print(df['long_summary'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a custom weighting system by assigning scores to each type of weather event based on severity or relevance. We weight it by evaluating the weather conditions, considering all three variables and visibility as visibility plays a significant role in determining whether weather conditions will impact driving safety. \n",
    "\n",
    "In order to calculate the weight, we first needed to understand how these variables reflect the weather on that specific date and assess how severe the conditions are for driving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = df[['icon', 'short_summary', 'long_summary']].drop_duplicates()\n",
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rain</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rain</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain in the morning and overnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icon       short_summary  \\\n",
       "1     rain          Light Rain    \n",
       "24    rain                Rain    \n",
       "33    rain             Drizzle    \n",
       "39    rain          Light Rain    \n",
       "43    rain             Drizzle    \n",
       "46    rain          Light Rain    \n",
       "85    rain          Light Rain    \n",
       "140   rain    Possible Drizzle    \n",
       "147   rain          Light Rain    \n",
       "198   rain    Possible Drizzle    \n",
       "205   rain    Possible Drizzle    \n",
       "229   rain    Possible Drizzle    \n",
       "278   rain                Rain    \n",
       "345   rain                Rain    \n",
       "\n",
       "                                          long_summary  \n",
       "1                           Light rain until evening.   \n",
       "24    Rain until morning, starting again in the eve...  \n",
       "33                         Light rain in the morning.   \n",
       "39                           Rain throughout the day.   \n",
       "43    Rain until morning, starting again in the eve...  \n",
       "46    Rain until morning, starting again in the eve...  \n",
       "85                         Light rain in the morning.   \n",
       "140                         Light rain until evening.   \n",
       "147          Light rain in the morning and overnight.   \n",
       "198   Rain until morning, starting again in the eve...  \n",
       "205                        Light rain in the morning.   \n",
       "229                          Rain throughout the day.   \n",
       "278                          Rain throughout the day.   \n",
       "345                        Light rain in the morning.   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' rain ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mostly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Overcast throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain in the morning and overnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Foggy in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Possible drizzle in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain in the morning and afternoon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          icon short_summary  \\\n",
       "2      cloudy      Overcast    \n",
       "5      cloudy      Overcast    \n",
       "6      cloudy      Overcast    \n",
       "8      cloudy      Overcast    \n",
       "16     cloudy      Overcast    \n",
       "17     cloudy      Overcast    \n",
       "28     cloudy      Overcast    \n",
       "36     cloudy      Overcast    \n",
       "89     cloudy      Overcast    \n",
       "933    cloudy      Overcast    \n",
       "2146   cloudy      Overcast    \n",
       "\n",
       "                                           long_summary  \n",
       "2                    Mostly cloudy throughout the day.   \n",
       "5      Rain until morning, starting again in the eve...  \n",
       "6                           Light rain in the morning.   \n",
       "8                         Overcast throughout the day.   \n",
       "16                   Partly cloudy throughout the day.   \n",
       "17                            Rain throughout the day.   \n",
       "28                           Light rain until evening.   \n",
       "36            Light rain in the morning and overnight.   \n",
       "89                               Foggy in the morning.   \n",
       "933                   Possible drizzle in the morning.   \n",
       "2146                Rain in the morning and afternoon.   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' cloudy ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Foggy in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Rain in the morning and afternoon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icon short_summary                                       long_summary\n",
       "32     fog         Foggy    Rain until morning, starting again in the eve...\n",
       "70     fog         Foggy                              Foggy in the morning. \n",
       "6997   fog         Foggy                 Rain in the morning and afternoon. "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' fog ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_severity(row):\n",
    "    # Initialize severity\n",
    "    severity = 1\n",
    "\n",
    "    if 'rain' in row['icon'].strip().lower():\n",
    "        # If rain is present in the icon, check for light or drizzle\n",
    "        if 'light' in row['short_summary'].lower() or 'drizzle' in row['short_summary'].lower() or \\\n",
    "           'light' in row['long_summary'].lower() or 'drizzle' in row['long_summary'].lower():\n",
    "            severity = 2  # Moderate severity for light rain or drizzle\n",
    "        else:\n",
    "            severity = 3  # Highest severity for rain without light or drizzle\n",
    "    elif 'cloudy' in row['icon'].lower() or 'fog' in row['icon'].lower():\n",
    "        severity = 2  # Moderate severity for clouds and fog\n",
    "\n",
    "    # Adjust severity based on visibility\n",
    "    if row['visibility'] < 1:  # Low visibility (less than 1)\n",
    "        severity += 1  # Increase severity by 1\n",
    "    elif row['visibility'] >= 7:  # High visibility (7 or more)\n",
    "        severity -= 1  # Decrease severity by 1\n",
    "        severity = max(severity, 1)  # Ensure severity doesn't go below 1\n",
    "\n",
    "    return severity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-related Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also added the following time related variables in week 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    # Create rush_hour feature\n",
    "    df['rush_hour'] = df['hour'].apply(lambda x: 1 if (6 <= x <= 9 or 16 <= x <= 18) else 0)\n",
    "\n",
    "    # Create weekend feature\n",
    "    df['weekend'] = df['datetime'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "    # Define game dates for Bruins and Celtics\n",
    "    bruins = [\n",
    "        '2018-11-05', '2018-11-08', '2018-11-10', '2018-11-11',\n",
    "        '2018-11-23', '2018-11-29', '2018-12-01', '2018-12-08',\n",
    "        '2018-12-11', '2018-12-16', '2018-12-20', '2018-12-22',\n",
    "        '2018-12-27'\n",
    "    ] \n",
    "    celtics = [\n",
    "        '2018-11-01', '2018-11-14', '2018-11-16', '2018-11-17',\n",
    "        '2018-11-21', '2018-11-30', '2018-12-06', '2018-12-10',\n",
    "        '2018-12-14', '2018-12-19', '2018-12-21', '2018-12-23',\n",
    "        '2018-12-25'\n",
    "    ]\n",
    "    game_dates = bruins + celtics\n",
    "\n",
    "    # Create game_day feature\n",
    "    df['game_day'] = df['datetime'].apply(lambda x: 1 if x.strftime('%Y-%m-%d') in game_dates else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_time_features(train_df)\n",
    "val_df = add_time_features(val_df)\n",
    "test_df = add_time_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_dt(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime']).dt.floor('h')\n",
    "    df['datetime'] = df['datetime'].dt.strftime('%Y-%m-%dT%H:00')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = shift_dt(train_df)\n",
    "val_df = shift_dt(val_df)\n",
    "test_df = shift_dt(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Since we conducted feature engineering on the original data before preprocessing, we will run the pipeline again to get the prepare the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Imputation\n",
    "Uber Taxi Fee Breakdown\n",
    " - base fare: $2.60 for first 1/7 mile\n",
    " - per minute fare: $0.47\n",
    " - per mile: $2.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_price_calculator(distance, time):\n",
    "    base_fare = 2.60\n",
    "    per_min_fare = 0.47\n",
    "    per_mile_fare = 2.8\n",
    "    price = base_fare + distance * per_mile_fare + time * per_min_fare\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_with_eta = os.path.join(interim_data_folder, \"rides_with_etas.csv\")\n",
    "rides_with_eta_rh = os.path.join(interim_data_folder, \"rides_with_etas_rush_hour.csv\")\n",
    "time_df = pd.read_csv(rides_with_eta)\n",
    "rh_time_df = pd.read_parquet(rides_with_eta_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_taxi_price(df: pd.DataFrame, time_df: pd.DataFrame, rush_hour = False) -> pd.DataFrame:\n",
    "    if rush_hour:\n",
    "         df = pd.merge(df, time_df, on=['source', 'destination', 'datetime'], how = 'left')\n",
    "         df.loc[df['name'] == 'Taxi', 'price'] = df.loc[df['name']== 'Taxi'].apply(lambda row: taxi_price_calculator(row['distance'], row['eta_minutes']), axis = 1)\n",
    "    else:\n",
    "        df = pd.merge(df, time_df, on=['source', 'destination'], how = 'left')\n",
    "        df.loc[df['name'] == 'Taxi', 'price'] = df.loc[df['name']== 'Taxi'].apply(lambda row: taxi_price_calculator(row['distance'], row['eta_minutes']), axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "rh_train_df = calculate_taxi_price(train_df, rh_time_df, rush_hour=True)\n",
    "rh_val_df = calculate_taxi_price(val_df, rh_time_df, rush_hour=True)\n",
    "rh_test_df = calculate_taxi_price(test_df, rh_time_df, rush_hour=True)\n",
    "\n",
    "train_df = calculate_taxi_price(train_df, time_df, rush_hour=False)\n",
    "val_df = calculate_taxi_price(val_df, time_df, rush_hour=False)\n",
    "test_df = calculate_taxi_price(test_df, time_df, rush_hour=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>timezone</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>...</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMaxTime</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>apparentTemperatureMinTime</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMaxTime</th>\n",
       "      <th>rush_hour</th>\n",
       "      <th>weekend</th>\n",
       "      <th>game_day</th>\n",
       "      <th>eta_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-27T08:00</td>\n",
       "      <td>1.543306e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>46.83</td>\n",
       "      <td>1543320000</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1543377600</td>\n",
       "      <td>43.85</td>\n",
       "      <td>1543320000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-14T14:00</td>\n",
       "      <td>1.544798e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Uber</td>\n",
       "      <td>6c84fd89-3f11-4782-9b50-97c468b19529</td>\n",
       "      <td>...</td>\n",
       "      <td>46.67</td>\n",
       "      <td>1544814000</td>\n",
       "      <td>24.47</td>\n",
       "      <td>1544785200</td>\n",
       "      <td>43.88</td>\n",
       "      <td>1544817600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-01T02:00</td>\n",
       "      <td>1.543633e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>...</td>\n",
       "      <td>42.57</td>\n",
       "      <td>1543600800</td>\n",
       "      <td>27.20</td>\n",
       "      <td>1543568400</td>\n",
       "      <td>40.51</td>\n",
       "      <td>1543611600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-03T07:00</td>\n",
       "      <td>1.543822e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North Station</td>\n",
       "      <td>North End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>6c84fd89-3f11-4782-9b50-97c468b19529</td>\n",
       "      <td>...</td>\n",
       "      <td>57.87</td>\n",
       "      <td>1543852800</td>\n",
       "      <td>39.41</td>\n",
       "      <td>1543896000</td>\n",
       "      <td>57.20</td>\n",
       "      <td>1543852800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-03T22:00</td>\n",
       "      <td>1.543875e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>North End</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>...</td>\n",
       "      <td>57.27</td>\n",
       "      <td>1543852800</td>\n",
       "      <td>39.54</td>\n",
       "      <td>1543896000</td>\n",
       "      <td>56.60</td>\n",
       "      <td>1543852800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime     timestamp  hour  day  month          timezone  \\\n",
       "0  2018-11-27T08:00  1.543306e+09     8   27     11  America/New_York   \n",
       "1  2018-12-14T14:00  1.544798e+09    14   14     12  America/New_York   \n",
       "2  2018-12-01T02:00  1.543633e+09     2    1     12  America/New_York   \n",
       "3  2018-12-03T07:00  1.543822e+09     7    3     12  America/New_York   \n",
       "4  2018-12-03T22:00  1.543875e+09    22    3     12  America/New_York   \n",
       "\n",
       "              source         destination cab_type  \\\n",
       "0  Boston University  Financial District     Lyft   \n",
       "1          North End            Back Bay     Uber   \n",
       "2      South Station    Theatre District     Lyft   \n",
       "3      North Station           North End     Uber   \n",
       "4          North End            Back Bay     Lyft   \n",
       "\n",
       "                             product_id  ... temperatureMax  \\\n",
       "0                                  lyft  ...          46.83   \n",
       "1  6c84fd89-3f11-4782-9b50-97c468b19529  ...          46.67   \n",
       "2                          lyft_premier  ...          42.57   \n",
       "3  6c84fd89-3f11-4782-9b50-97c468b19529  ...          57.87   \n",
       "4                          lyft_premier  ...          57.27   \n",
       "\n",
       "   temperatureMaxTime  apparentTemperatureMin  apparentTemperatureMinTime  \\\n",
       "0          1543320000                   32.05                  1543377600   \n",
       "1          1544814000                   24.47                  1544785200   \n",
       "2          1543600800                   27.20                  1543568400   \n",
       "3          1543852800                   39.41                  1543896000   \n",
       "4          1543852800                   39.54                  1543896000   \n",
       "\n",
       "   apparentTemperatureMax  apparentTemperatureMaxTime  rush_hour  weekend  \\\n",
       "0                   43.85                  1543320000          1        0   \n",
       "1                   43.88                  1544817600          0        0   \n",
       "2                   40.51                  1543611600          0        1   \n",
       "3                   57.20                  1543852800          1        0   \n",
       "4                   56.60                  1543852800          0        0   \n",
       "\n",
       "  game_day eta_minutes  \n",
       "0        0       19.62  \n",
       "1        1       18.25  \n",
       "2        1        6.69  \n",
       "3        0        4.43  \n",
       "4        0       13.32  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing value in train_df: 0\n",
      "Number of missing value in val_df: 0\n",
      "Number of missing value in test_df: 0\n",
      "Number of missing value in rh_train_df: 0\n",
      "Number of missing value in rh_val_df: 0\n",
      "Number of missing value in rh_test_df: 0\n"
     ]
    }
   ],
   "source": [
    "train_na = train_df[train_df['name']==\"Taxi\"]['price'].isnull().sum()\n",
    "val_na = val_df[val_df['name']==\"Taxi\"]['price'].isnull().sum()\n",
    "test_na = test_df[test_df['name']==\"Taxi\"]['price'].isnull().sum()\n",
    "print(f'Number of missing value in train_df: {test_na}')\n",
    "print(f'Number of missing value in val_df: {val_na}')\n",
    "print(f'Number of missing value in test_df: {test_na}')\n",
    "rh_train_na = rh_train_df[rh_train_df['name']==\"Taxi\"]['price'].isnull().sum()\n",
    "rh_val_na = rh_val_df[rh_val_df['name']==\"Taxi\"]['price'].isnull().sum()\n",
    "rh_test_na = rh_test_df[rh_test_df['name']==\"Taxi\"]['price'].isnull().sum()\n",
    "print(f'Number of missing value in rh_train_df: {rh_train_na}')\n",
    "print(f'Number of missing value in rh_val_df: {rh_val_na}')\n",
    "print(f'Number of missing value in rh_test_df: {rh_test_na}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Uneeded Columns\n",
    "Some columns are not relevant for modeling because they function solely as unique identifiers and do not provide meaningful information for preduction purposes:\n",
    "- `id`\n",
    "- `product_id`\n",
    "\n",
    "Additionally, we also dropped `timezone` since all data is within the same timezone.\n",
    "\n",
    "`datetime` and`timestamp` were dropped to reduce redundacy with other time features.\n",
    "\n",
    "`visibility.1` is duplicated with  `visibility`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['timezone', 'datetime', 'product_id', 'visibility.1', 'timestamp','short_summary', 'long_summary', 'icon']\n",
    "\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "val_df = val_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "rh_train_df = rh_train_df.drop(columns=columns_to_drop)\n",
    "rh_val_df = rh_val_df.drop(columns=columns_to_drop)\n",
    "rh_test_df = rh_test_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had previously dropped the variable `eta_minutes` as well, but we added this variable back in for week 10. We hope to identify whether including this variable improves the performance of our winning model, the pruned Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "#### Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Columns:\n",
      "['source', 'destination', 'cab_type', 'name']\n"
     ]
    }
   ],
   "source": [
    "object_columns = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Display the object columns\n",
    "print(\"Object Columns:\")\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Encoding `source` and `destination` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['source'] = train_df['source'].str.strip().str.replace(' ', '_')\n",
    "val_df['source'] = val_df['source'].str.strip().str.replace(' ', '_')\n",
    "test_df['source'] = test_df['source'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'source' column\n",
    "train_encoded_summary = encoder.fit_transform(train_df[['source']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_summary = encoder.transform(val_df[['source']])\n",
    "test_encoded_summary = encoder.transform(test_df[['source']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_summary_df = pd.DataFrame(train_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "val_encoded_summary_df = pd.DataFrame(val_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "test_encoded_summary_df = pd.DataFrame(test_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'source' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_summary_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_summary_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_train_df['source'] = rh_train_df['source'].str.strip().str.replace(' ', '_')\n",
    "rh_val_df['source'] = rh_val_df['source'].str.strip().str.replace(' ', '_')\n",
    "rh_test_df['source'] = rh_test_df['source'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'source' column\n",
    "rh_train_encoded_summary = encoder.fit_transform(rh_train_df[['source']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "rh_val_encoded_summary = encoder.transform(rh_val_df[['source']])\n",
    "rh_test_encoded_summary = encoder.transform(rh_test_df[['source']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "rh_train_encoded_summary_df = pd.DataFrame(rh_train_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "rh_val_encoded_summary_df = pd.DataFrame(rh_val_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "rh_test_encoded_summary_df = pd.DataFrame(rh_test_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'source' columns back to the respective datasets\n",
    "rh_train_df = pd.concat([rh_train_df.reset_index(drop=True), rh_train_encoded_summary_df], axis=1)\n",
    "rh_val_df = pd.concat([rh_val_df.reset_index(drop=True), rh_val_encoded_summary_df], axis=1)\n",
    "rh_test_df = pd.concat([rh_test_df.reset_index(drop=True), rh_test_encoded_summary_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the categories from the fitted OneHotEncoder for 'source'\n",
    "source_categories = encoder.categories_[0]\n",
    "\n",
    "# Initialize a new OneHotEncoder for 'destination'\n",
    "destination_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Strip leading/trailing spaces and replace blank spaces with underscores in the destination column\n",
    "train_df['destination'] = train_df['destination'].str.strip().str.replace(' ', '_')\n",
    "val_df['destination'] = val_df['destination'].str.strip().str.replace(' ', '_')\n",
    "test_df['destination'] = test_df['destination'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Fit the encoder on the training data 'destination' column\n",
    "train_encoded_destination = destination_encoder.fit_transform(train_df[['destination']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_destination = destination_encoder.transform(val_df[['destination']])\n",
    "test_encoded_destination = destination_encoder.transform(test_df[['destination']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_destination_df = pd.DataFrame(train_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "val_encoded_destination_df = pd.DataFrame(val_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "test_encoded_destination_df = pd.DataFrame(test_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'destination' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_destination_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_destination_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_destination_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the categories from the fitted OneHotEncoder for 'source'\n",
    "source_categories = encoder.categories_[0]\n",
    "\n",
    "# Initialize a new OneHotEncoder for 'destination'\n",
    "destination_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Strip leading/trailing spaces and replace blank spaces with underscores in the destination column\n",
    "rh_train_df['destination'] = rh_train_df['destination'].str.strip().str.replace(' ', '_')\n",
    "rh_val_df['destination'] = rh_val_df['destination'].str.strip().str.replace(' ', '_')\n",
    "rh_test_df['destination'] = rh_test_df['destination'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Fit the encoder on the training data 'destination' column\n",
    "rh_train_encoded_destination = destination_encoder.fit_transform(rh_train_df[['destination']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "rh_val_encoded_destination = destination_encoder.transform(rh_val_df[['destination']])\n",
    "rh_test_encoded_destination = destination_encoder.transform(rh_test_df[['destination']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "rh_train_encoded_destination_df = pd.DataFrame(rh_train_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "rh_val_encoded_destination_df = pd.DataFrame(rh_val_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "rh_test_encoded_destination_df = pd.DataFrame(rh_test_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'destination' columns back to the respective datasets\n",
    "rh_train_df = pd.concat([rh_train_df.reset_index(drop=True), rh_train_encoded_destination_df], axis=1)\n",
    "rh_val_df = pd.concat([rh_val_df.reset_index(drop=True), rh_val_encoded_destination_df], axis=1)\n",
    "rh_test_df = pd.concat([rh_test_df.reset_index(drop=True), rh_test_encoded_destination_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding 'cab_type' and 'name' variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['name'] = train_df['name'].str.strip().str.replace(' ', '_')\n",
    "val_df['name'] = val_df['name'].str.strip().str.replace(' ', '_')\n",
    "test_df['name'] = test_df['name'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'name' column\n",
    "train_encoded_summary = encoder.fit_transform(train_df[['name']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_summary = encoder.transform(val_df[['name']])\n",
    "test_encoded_summary = encoder.transform(test_df[['name']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_summary_df = pd.DataFrame(train_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "val_encoded_summary_df = pd.DataFrame(val_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "test_encoded_summary_df = pd.DataFrame(test_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'name' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_summary_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_summary_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_train_df['name'] = rh_train_df['name'].str.strip().str.replace(' ', '_')\n",
    "rh_val_df['name'] = rh_val_df['name'].str.strip().str.replace(' ', '_')\n",
    "rh_test_df['name'] = rh_test_df['name'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'name' column\n",
    "rh_train_encoded_summary = encoder.fit_transform(rh_train_df[['name']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "rh_val_encoded_summary = encoder.transform(rh_val_df[['name']])\n",
    "rh_test_encoded_summary = encoder.transform(rh_test_df[['name']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "rh_train_encoded_summary_df = pd.DataFrame(rh_train_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "rh_val_encoded_summary_df = pd.DataFrame(rh_val_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "rh_test_encoded_summary_df = pd.DataFrame(rh_test_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'name' columns back to the respective datasets\n",
    "rh_train_df = pd.concat([rh_train_df.reset_index(drop=True), rh_train_encoded_summary_df], axis=1)\n",
    "rh_val_df = pd.concat([rh_val_df.reset_index(drop=True), rh_val_encoded_summary_df], axis=1)\n",
    "rh_test_df = pd.concat([rh_test_df.reset_index(drop=True), rh_test_encoded_summary_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cab_type'] = train_df['cab_type'].str.strip()\n",
    "val_df['cab_type'] = val_df['cab_type'].str.strip()\n",
    "test_df['cab_type'] = test_df['cab_type'].str.strip()\n",
    "\n",
    "# Ensure there are no leading or trailing spaces in the 'cab_type' column\n",
    "train_df['cab_type'] = train_df['cab_type'].str.strip()\n",
    "val_df['cab_type'] = val_df['cab_type'].str.strip()\n",
    "test_df['cab_type'] = test_df['cab_type'].str.strip()\n",
    "\n",
    "# Create dummy variables for the 'cab_type' column\n",
    "train_df = pd.get_dummies(train_df, columns=['cab_type'], drop_first=True)\n",
    "val_df = pd.get_dummies(val_df, columns=['cab_type'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=['cab_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_train_df['cab_type'] = rh_train_df['cab_type'].str.strip()\n",
    "rh_val_df['cab_type'] = rh_val_df['cab_type'].str.strip()\n",
    "rh_test_df['cab_type'] = rh_test_df['cab_type'].str.strip()\n",
    "\n",
    "# Ensure there are no leading or trailing spaces in the 'cab_type' column\n",
    "rh_train_df['cab_type'] = rh_train_df['cab_type'].str.strip()\n",
    "rh_val_df['cab_type'] = rh_val_df['cab_type'].str.strip()\n",
    "rh_test_df['cab_type'] = rh_test_df['cab_type'].str.strip()\n",
    "\n",
    "# Create dummy variables for the 'cab_type' column\n",
    "rh_train_df = pd.get_dummies(rh_train_df, columns=['cab_type'], drop_first=True)\n",
    "rh_val_df = pd.get_dummies(rh_val_df, columns=['cab_type'], drop_first=True)\n",
    "rh_test_df = pd.get_dummies(rh_test_df, columns=['cab_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop encoded categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns_to_drop = ['source',\n",
    " 'destination',\n",
    " 'name']\n",
    "\n",
    "train_df = train_df.drop(columns = cat_columns_to_drop)\n",
    "val_df = val_df.drop(columns = cat_columns_to_drop)\n",
    "test_df = test_df.drop(columns = cat_columns_to_drop)\n",
    "\n",
    "rh_train_df = rh_train_df.drop(columns=cat_columns_to_drop)\n",
    "rh_val_df = rh_val_df.drop(columns=cat_columns_to_drop)\n",
    "rh_test_df = rh_test_df.drop(columns=cat_columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 86)\n",
      "(70000, 86)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(rh_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'day', 'month', 'price', 'distance', 'surge_multiplier',\n",
       "       'latitude', 'longitude', 'temperature', 'apparentTemperature',\n",
       "       'precipIntensity', 'precipProbability', 'humidity', 'windSpeed',\n",
       "       'windGust', 'windGustTime', 'visibility', 'temperatureHigh',\n",
       "       'temperatureHighTime', 'temperatureLow', 'temperatureLowTime',\n",
       "       'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
       "       'apparentTemperatureLow', 'apparentTemperatureLowTime', 'dewPoint',\n",
       "       'pressure', 'windBearing', 'cloudCover', 'uvIndex', 'ozone',\n",
       "       'sunriseTime', 'sunsetTime', 'moonPhase', 'precipIntensityMax',\n",
       "       'uvIndexTime', 'temperatureMin', 'temperatureMinTime', 'temperatureMax',\n",
       "       'temperatureMaxTime', 'apparentTemperatureMin',\n",
       "       'apparentTemperatureMinTime', 'apparentTemperatureMax',\n",
       "       'apparentTemperatureMaxTime', 'rush_hour', 'weekend', 'game_day',\n",
       "       'eta_minutes', 'source_Back_Bay', 'source_Beacon_Hill',\n",
       "       'source_Boston_University', 'source_Fenway',\n",
       "       'source_Financial_District', 'source_Haymarket_Square',\n",
       "       'source_North_End', 'source_North_Station',\n",
       "       'source_Northeastern_University', 'source_South_Station',\n",
       "       'source_Theatre_District', 'source_West_End', 'destination_Back_Bay',\n",
       "       'destination_Beacon_Hill', 'destination_Boston_University',\n",
       "       'destination_Fenway', 'destination_Financial_District',\n",
       "       'destination_Haymarket_Square', 'destination_North_End',\n",
       "       'destination_North_Station', 'destination_Northeastern_University',\n",
       "       'destination_South_Station', 'destination_Theatre_District',\n",
       "       'destination_West_End', 'name_Black', 'name_Black_SUV', 'name_Lux',\n",
       "       'name_Lux_Black', 'name_Lux_Black_XL', 'name_Lyft', 'name_Lyft_XL',\n",
       "       'name_Shared', 'name_Taxi', 'name_UberPool', 'name_UberX',\n",
       "       'name_UberXL', 'name_WAV', 'cab_type_Uber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'day', 'month', 'price', 'distance', 'surge_multiplier',\n",
       "       'latitude', 'longitude', 'temperature', 'apparentTemperature',\n",
       "       'precipIntensity', 'precipProbability', 'humidity', 'windSpeed',\n",
       "       'windGust', 'windGustTime', 'visibility', 'temperatureHigh',\n",
       "       'temperatureHighTime', 'temperatureLow', 'temperatureLowTime',\n",
       "       'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
       "       'apparentTemperatureLow', 'apparentTemperatureLowTime', 'dewPoint',\n",
       "       'pressure', 'windBearing', 'cloudCover', 'uvIndex', 'ozone',\n",
       "       'sunriseTime', 'sunsetTime', 'moonPhase', 'precipIntensityMax',\n",
       "       'uvIndexTime', 'temperatureMin', 'temperatureMinTime', 'temperatureMax',\n",
       "       'temperatureMaxTime', 'apparentTemperatureMin',\n",
       "       'apparentTemperatureMinTime', 'apparentTemperatureMax',\n",
       "       'apparentTemperatureMaxTime', 'rush_hour', 'weekend', 'game_day',\n",
       "       'eta_minutes', 'source_Back_Bay', 'source_Beacon_Hill',\n",
       "       'source_Boston_University', 'source_Fenway',\n",
       "       'source_Financial_District', 'source_Haymarket_Square',\n",
       "       'source_North_End', 'source_North_Station',\n",
       "       'source_Northeastern_University', 'source_South_Station',\n",
       "       'source_Theatre_District', 'source_West_End', 'destination_Back_Bay',\n",
       "       'destination_Beacon_Hill', 'destination_Boston_University',\n",
       "       'destination_Fenway', 'destination_Financial_District',\n",
       "       'destination_Haymarket_Square', 'destination_North_End',\n",
       "       'destination_North_Station', 'destination_Northeastern_University',\n",
       "       'destination_South_Station', 'destination_Theatre_District',\n",
       "       'destination_West_End', 'name_Black', 'name_Black_SUV', 'name_Lux',\n",
       "       'name_Lux_Black', 'name_Lux_Black_XL', 'name_Lyft', 'name_Lyft_XL',\n",
       "       'name_Shared', 'name_Taxi', 'name_UberPool', 'name_UberX',\n",
       "       'name_UberXL', 'name_WAV', 'cab_type_Uber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and PCA\n",
    "#### Let's standardize our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[['price']]\n",
    "y_val = val_df[['price']]\n",
    "y_test = test_df[['price']]\n",
    "\n",
    "X_train = train_df.drop('price', axis = 1)\n",
    "X_val = val_df.drop('price', axis = 1)\n",
    "X_test = test_df.drop('price', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_y_train = rh_train_df[['price']]\n",
    "rh_y_val = rh_val_df[['price']]\n",
    "rh_y_test = rh_test_df[['price']]\n",
    "\n",
    "rh_X_train = rh_train_df.drop('price', axis=1)\n",
    "rh_X_val = rh_val_df.drop('price', axis=1)\n",
    "rh_X_test = rh_test_df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "rh_X_train_scaled = scaler.fit_transform(rh_X_train)\n",
    "rh_X_val_scaled = scaler.transform(rh_X_val)\n",
    "rh_X_test_scaled = scaler.transform(rh_X_test)\n",
    "\n",
    "rh_X_train_scaled = pd.DataFrame(rh_X_train_scaled, columns=rh_X_train.columns)\n",
    "rh_X_val_scaled = pd.DataFrame(rh_X_val_scaled, columns=rh_X_val.columns)\n",
    "rh_X_test_scaled = pd.DataFrame(rh_X_test_scaled, columns=rh_X_test.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train the Pruned Decision Tree Model using enhanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mse = rmse**2\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(ccp_alpha=0.001, max_depth=20, min_samples_leaf=10,\n",
       "                      min_samples_split=7, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor(ccp_alpha=0.001, max_depth=20, min_samples_leaf=10,\n",
       "                      min_samples_split=7, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.001, max_depth=20, min_samples_leaf=10,\n",
       "                      min_samples_split=7, random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(\n",
    "    max_depth=20,\n",
    "    min_samples_split=7,\n",
    "    min_samples_leaf=10,\n",
    "    ccp_alpha=0.001,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "dtr.fit(X_train_scaled, y_train)\n",
    "\n",
    "dtr_rh = DecisionTreeRegressor(\n",
    "    max_depth=20,\n",
    "    min_samples_split=7,\n",
    "    min_samples_leaf=10,\n",
    "    ccp_alpha=0.001,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "dtr_rh.fit(rh_X_train_scaled, rh_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Model (dtr) - Training Metrics:\n",
      "MSE: 2.6491, RMSE: 1.6276, R²: 0.9679\n",
      "\n",
      "Decision Tree Regression Model (dtr) - Validation Metrics:\n",
      "MSE: 3.0253, RMSE: 1.7393, R²: 0.9630\n",
      "\n",
      "Decision Tree Regression Model (dtr) - Test Metrics:\n",
      "MSE: 3.0488, RMSE: 1.7461, R²: 0.9635\n",
      "\n",
      "Decision Tree Regression Model (dtr_rh) - Training Metrics:\n",
      "MSE: 2.6874, RMSE: 1.6393, R²: 0.9675\n",
      "\n",
      "Decision Tree Regression Model (dtr_rh) - Validation Metrics:\n",
      "MSE: 3.0487, RMSE: 1.7460, R²: 0.9628\n",
      "\n",
      "Decision Tree Regression Model (dtr_rh) - Test Metrics:\n",
      "MSE: 3.0047, RMSE: 1.7334, R²: 0.9641\n"
     ]
    }
   ],
   "source": [
    "# Predicting on training, validation, and test sets for the first decision tree (dtr)\n",
    "y_train_pred_tree = dtr.predict(X_train_scaled)\n",
    "y_val_pred_tree = dtr.predict(X_val_scaled)\n",
    "y_test_pred_tree = dtr.predict(X_test_scaled)\n",
    "\n",
    "# Predicting on training, validation, and test sets for the second decision tree (dtr_rh)\n",
    "rh_y_train_pred_tree = dtr_rh.predict(rh_X_train_scaled)\n",
    "rh_y_val_pred_tree = dtr_rh.predict(rh_X_val_scaled)\n",
    "rh_y_test_pred_tree = dtr_rh.predict(rh_X_test_scaled)\n",
    "\n",
    "# Evaluate performance for the first decision tree (dtr)\n",
    "train_mse_tree, train_rmse_tree, train_r2_tree = evaluate_model(y_train, y_train_pred_tree)\n",
    "val_mse_tree, val_rmse_tree, val_r2_tree = evaluate_model(y_val, y_val_pred_tree)\n",
    "test_mse_tree, test_rmse_tree, test_r2_tree = evaluate_model(y_test, y_test_pred_tree)\n",
    "\n",
    "# Evaluate performance for the second decision tree (dtr_rh)\n",
    "rh_train_mse_tree, rh_train_rmse_tree, rh_train_r2_tree = evaluate_model(rh_y_train, rh_y_train_pred_tree)\n",
    "rh_val_mse_tree, rh_val_rmse_tree, rh_val_r2_tree = evaluate_model(rh_y_val, rh_y_val_pred_tree)\n",
    "rh_test_mse_tree, rh_test_rmse_tree, rh_test_r2_tree = evaluate_model(rh_y_test, rh_y_test_pred_tree)\n",
    "\n",
    "# Print training metrics for dtr\n",
    "print(\"Decision Tree Regression Model (dtr) - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_tree:.4f}, RMSE: {train_rmse_tree:.4f}, R²: {train_r2_tree:.4f}\")\n",
    "\n",
    "# Print validation metrics for dtr\n",
    "print(\"\\nDecision Tree Regression Model (dtr) - Validation Metrics:\")\n",
    "print(f\"MSE: {val_mse_tree:.4f}, RMSE: {val_rmse_tree:.4f}, R²: {val_r2_tree:.4f}\")\n",
    "\n",
    "# Print test metrics for dtr\n",
    "print(\"\\nDecision Tree Regression Model (dtr) - Test Metrics:\")\n",
    "print(f\"MSE: {test_mse_tree:.4f}, RMSE: {test_rmse_tree:.4f}, R²: {test_r2_tree:.4f}\")\n",
    "\n",
    "# Print training metrics for dtr_rh\n",
    "print(\"\\nDecision Tree Regression Model (dtr_rh) - Training Metrics:\")\n",
    "print(f\"MSE: {rh_train_mse_tree:.4f}, RMSE: {rh_train_rmse_tree:.4f}, R²: {rh_train_r2_tree:.4f}\")\n",
    "\n",
    "# Print validation metrics for dtr_rh\n",
    "print(\"\\nDecision Tree Regression Model (dtr_rh) - Validation Metrics:\")\n",
    "print(f\"MSE: {rh_val_mse_tree:.4f}, RMSE: {rh_val_rmse_tree:.4f}, R²: {rh_val_r2_tree:.4f}\")\n",
    "\n",
    "# Print test metrics for dtr_rh\n",
    "print(\"\\nDecision Tree Regression Model (dtr_rh) - Test Metrics:\")\n",
    "print(f\"MSE: {rh_test_mse_tree:.4f}, RMSE: {rh_test_rmse_tree:.4f}, R²: {rh_test_r2_tree:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
