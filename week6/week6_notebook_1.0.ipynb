{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Notebook: Model training, hyperparameter tuning, and model evaluation\n",
    "The goal of this week's assignment is to use one modeling method with 3 different hyperparameter settings of the method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "processed_data_folder = os.path.join(data_folder, \"processed\")\n",
    "\n",
    "raw_data_file = os.path.join(raw_data_folder, 'rawSampledData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'timestamp', 'hour', 'day', 'month', 'timezone', 'source',\n",
      "       'destination', 'cab_type', 'product_id', 'name', 'price', 'distance',\n",
      "       'surge_multiplier', 'latitude', 'longitude', 'temperature',\n",
      "       'apparentTemperature', 'short_summary', 'long_summary',\n",
      "       'precipIntensity', 'precipProbability', 'humidity', 'windSpeed',\n",
      "       'windGust', 'windGustTime', 'visibility', 'temperatureHigh',\n",
      "       'temperatureHighTime', 'temperatureLow', 'temperatureLowTime',\n",
      "       'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
      "       'apparentTemperatureLow', 'apparentTemperatureLowTime', 'icon',\n",
      "       'dewPoint', 'pressure', 'windBearing', 'cloudCover', 'uvIndex',\n",
      "       'visibility.1', 'ozone', 'sunriseTime', 'sunsetTime', 'moonPhase',\n",
      "       'precipIntensityMax', 'uvIndexTime', 'temperatureMin',\n",
      "       'temperatureMinTime', 'temperatureMax', 'temperatureMaxTime',\n",
      "       'apparentTemperatureMin', 'apparentTemperatureMinTime',\n",
      "       'apparentTemperatureMax', 'apparentTemperatureMaxTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe.\n",
    "df = pd.read_csv(raw_data_file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>timezone</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>...</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>uvIndexTime</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>temperatureMinTime</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMaxTime</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>apparentTemperatureMinTime</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMaxTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-13 20:40:15</td>\n",
       "      <td>1.544734e+09</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>18.29</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.83</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.79</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.85</td>\n",
       "      <td>1544734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-02 09:53:05</td>\n",
       "      <td>1.543744e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>Uber</td>\n",
       "      <td>8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>1543770000</td>\n",
       "      <td>36.40</td>\n",
       "      <td>1543726800</td>\n",
       "      <td>50.94</td>\n",
       "      <td>1543788000</td>\n",
       "      <td>35.78</td>\n",
       "      <td>1543748400</td>\n",
       "      <td>50.27</td>\n",
       "      <td>1543788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-28 21:53:08</td>\n",
       "      <td>1.543442e+09</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1543420800</td>\n",
       "      <td>33.70</td>\n",
       "      <td>1543399200</td>\n",
       "      <td>42.60</td>\n",
       "      <td>1543438800</td>\n",
       "      <td>29.88</td>\n",
       "      <td>1543399200</td>\n",
       "      <td>36.56</td>\n",
       "      <td>1543435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-13 05:15:05</td>\n",
       "      <td>1.544678e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1544716800</td>\n",
       "      <td>17.98</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>33.82</td>\n",
       "      <td>1544731200</td>\n",
       "      <td>13.52</td>\n",
       "      <td>1544688000</td>\n",
       "      <td>32.84</td>\n",
       "      <td>1544734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-02 09:48:00</td>\n",
       "      <td>1.543744e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Uber</td>\n",
       "      <td>6d318bcc-22a3-4af6-bddd-b409bfce1546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>1543770000</td>\n",
       "      <td>36.40</td>\n",
       "      <td>1543726800</td>\n",
       "      <td>50.94</td>\n",
       "      <td>1543788000</td>\n",
       "      <td>35.78</td>\n",
       "      <td>1543748400</td>\n",
       "      <td>50.27</td>\n",
       "      <td>1543788000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime     timestamp  hour  day  month          timezone  \\\n",
       "0  2018-12-13 20:40:15  1.544734e+09    20   13     12  America/New_York   \n",
       "1  2018-12-02 09:53:05  1.543744e+09     9    2     12  America/New_York   \n",
       "2  2018-11-28 21:53:08  1.543442e+09    21   28     11  America/New_York   \n",
       "3  2018-12-13 05:15:05  1.544678e+09     5   13     12  America/New_York   \n",
       "4  2018-12-02 09:48:00  1.543744e+09     9    2     12  America/New_York   \n",
       "\n",
       "                    source       destination cab_type  \\\n",
       "0         Theatre District            Fenway     Lyft   \n",
       "1              Beacon Hill  Haymarket Square     Uber   \n",
       "2  Northeastern University     North Station     Lyft   \n",
       "3                   Fenway          Back Bay     Lyft   \n",
       "4  Northeastern University       Beacon Hill     Uber   \n",
       "\n",
       "                             product_id  ... precipIntensityMax  uvIndexTime  \\\n",
       "0                             lyft_plus  ...             0.0001   1544716800   \n",
       "1  8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a  ...             0.0894   1543770000   \n",
       "2                                  lyft  ...             0.0000   1543420800   \n",
       "3                           lyft_luxsuv  ...             0.0001   1544716800   \n",
       "4  6d318bcc-22a3-4af6-bddd-b409bfce1546  ...             0.0894   1543770000   \n",
       "\n",
       "   temperatureMin  temperatureMinTime  temperatureMax  temperatureMaxTime  \\\n",
       "0           18.29          1544688000           33.83          1544731200   \n",
       "1           36.40          1543726800           50.94          1543788000   \n",
       "2           33.70          1543399200           42.60          1543438800   \n",
       "3           17.98          1544688000           33.82          1544731200   \n",
       "4           36.40          1543726800           50.94          1543788000   \n",
       "\n",
       "   apparentTemperatureMin  apparentTemperatureMinTime apparentTemperatureMax  \\\n",
       "0                   13.79                  1544688000                  32.85   \n",
       "1                   35.78                  1543748400                  50.27   \n",
       "2                   29.88                  1543399200                  36.56   \n",
       "3                   13.52                  1544688000                  32.84   \n",
       "4                   35.78                  1543748400                  50.27   \n",
       "\n",
       "  apparentTemperatureMaxTime  \n",
       "0                 1544734800  \n",
       "1                 1543788000  \n",
       "2                 1543435200  \n",
       "3                 1544734800  \n",
       "4                 1543788000  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training, testing, and validation sets\n",
    "- training set is 70% of the dataframe\n",
    "- validation set is 20% of the dataframe\n",
    "- test set is 10% of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df):\n",
    "    # Shuffle the dataset and calculate the size of validation and test sets\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123)\n",
    "\n",
    "    val_size = int(len(df) * 0.2)\n",
    "    test_size = int(len(df) * 0.1)\n",
    "\n",
    "    # Select rows based on the val_size and test_size to store as train set, val set, and test set\n",
    "    train_df = df.iloc[val_size + test_size:]\n",
    "    val_df = df.iloc[:val_size]\n",
    "    test_df = df.iloc[val_size:val_size + test_size]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new variables\n",
    "#### Weather-related Variable\n",
    "There are several variables, `icon`, `short_summary`, and `long_summary`, that are very similar in its context. We are thinking about combining them into one variable to reduce redundancy and dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes of icon:\n",
      "[' partly-cloudy-day ' ' rain ' ' cloudy ' ' clear-night ' ' clear-day '\n",
      " ' partly-cloudy-night ' ' fog ']\n",
      "\n",
      "Unique classes of short_summary:\n",
      "[' Mostly Cloudy ' ' Light Rain ' ' Overcast ' ' Clear ' ' Partly Cloudy '\n",
      " ' Rain ' ' Foggy ' ' Drizzle ' ' Possible Drizzle ']\n",
      "\n",
      "Unique classes of long_summary:\n",
      "[' Partly cloudy throughout the day. ' ' Light rain until evening. '\n",
      " ' Mostly cloudy throughout the day. '\n",
      " ' Rain until morning, starting again in the evening. '\n",
      " ' Light rain in the morning. ' ' Overcast throughout the day. '\n",
      " ' Foggy in the morning. ' ' Light rain in the morning and overnight. '\n",
      " ' Rain throughout the day. ' ' Possible drizzle in the morning. '\n",
      " ' Rain in the morning and afternoon. ']\n"
     ]
    }
   ],
   "source": [
    "print('Unique classes of icon:')\n",
    "print(df['icon'].unique())\n",
    "print('')\n",
    "print('Unique classes of short_summary:')\n",
    "print(df['short_summary'].unique())\n",
    "print('')\n",
    "print('Unique classes of long_summary:')\n",
    "print(df['long_summary'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can appraoch the problem is to create a custom weighting system by assigning scores to each type of weather event based on severity or relevance. We weight it by evaluating the weather conditions, considering all three variables and visibility as visibility plays a significant role in determining whether weather conditions will impact driving safety. \n",
    "\n",
    "In order to calculate the weight, we first need to understand how these variables reflect the weather on that specific date and assess how severe the conditions are for driving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = df[['icon', 'short_summary', 'long_summary']].drop_duplicates()\n",
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rain</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rain</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>rain</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>Light rain in the morning and overnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>rain</td>\n",
       "      <td>Possible Drizzle</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>rain</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icon       short_summary  \\\n",
       "1     rain          Light Rain    \n",
       "24    rain                Rain    \n",
       "33    rain             Drizzle    \n",
       "39    rain          Light Rain    \n",
       "43    rain             Drizzle    \n",
       "46    rain          Light Rain    \n",
       "85    rain          Light Rain    \n",
       "140   rain    Possible Drizzle    \n",
       "147   rain          Light Rain    \n",
       "198   rain    Possible Drizzle    \n",
       "205   rain    Possible Drizzle    \n",
       "229   rain    Possible Drizzle    \n",
       "278   rain                Rain    \n",
       "345   rain                Rain    \n",
       "\n",
       "                                          long_summary  \n",
       "1                           Light rain until evening.   \n",
       "24    Rain until morning, starting again in the eve...  \n",
       "33                         Light rain in the morning.   \n",
       "39                           Rain throughout the day.   \n",
       "43    Rain until morning, starting again in the eve...  \n",
       "46    Rain until morning, starting again in the eve...  \n",
       "85                         Light rain in the morning.   \n",
       "140                         Light rain until evening.   \n",
       "147          Light rain in the morning and overnight.   \n",
       "198   Rain until morning, starting again in the eve...  \n",
       "205                        Light rain in the morning.   \n",
       "229                          Rain throughout the day.   \n",
       "278                          Rain throughout the day.   \n",
       "345                        Light rain in the morning.   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' rain ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mostly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Overcast throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain until evening.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Light rain in the morning and overnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Foggy in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Possible drizzle in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Rain in the morning and afternoon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          icon short_summary  \\\n",
       "2      cloudy      Overcast    \n",
       "5      cloudy      Overcast    \n",
       "6      cloudy      Overcast    \n",
       "8      cloudy      Overcast    \n",
       "16     cloudy      Overcast    \n",
       "17     cloudy      Overcast    \n",
       "28     cloudy      Overcast    \n",
       "36     cloudy      Overcast    \n",
       "89     cloudy      Overcast    \n",
       "933    cloudy      Overcast    \n",
       "2146   cloudy      Overcast    \n",
       "\n",
       "                                           long_summary  \n",
       "2                    Mostly cloudy throughout the day.   \n",
       "5      Rain until morning, starting again in the eve...  \n",
       "6                           Light rain in the morning.   \n",
       "8                         Overcast throughout the day.   \n",
       "16                   Partly cloudy throughout the day.   \n",
       "17                            Rain throughout the day.   \n",
       "28                           Light rain until evening.   \n",
       "36            Light rain in the morning and overnight.   \n",
       "89                               Foggy in the morning.   \n",
       "933                   Possible drizzle in the morning.   \n",
       "2146                Rain in the morning and afternoon.   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' cloudy ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icon</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>long_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Rain until morning, starting again in the eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Foggy in the morning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>fog</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Rain in the morning and afternoon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icon short_summary                                       long_summary\n",
       "32     fog         Foggy    Rain until morning, starting again in the eve...\n",
       "70     fog         Foggy                              Foggy in the morning. \n",
       "6997   fog         Foggy                 Rain in the morning and afternoon. "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[weather_df['icon'] == ' fog ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precipitation intensity between 0.1 to 0.4 in/h indicates steady rain, which may cause minor inconveniences but typically does not result in flooding. There is no indication of severe rain in our data. However, visibility below 1 mile can significantly impact driving conditions. As a result, we plan to incorporate visibility into our approach for weighting the effects of weather.\n",
    "\n",
    "- By default, every row's weather severity condition is set to 1. \n",
    "- If the rain classified as anything other than \"light\", we assign it a severity level of 3 (indicating the highest severity).\n",
    "- For all other conditions (cloudy, foggy, or light rain), we assign as severity level of 2. \n",
    "- Since there are no instances of severe rain in the dataset, we will adjust the severity score further based on visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008998</td>\n",
       "      <td>8.463778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027040</td>\n",
       "      <td>2.603025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.144700</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precipIntensity     visibility\n",
       "count    100000.000000  100000.000000\n",
       "mean          0.008998       8.463778\n",
       "std           0.027040       2.603025\n",
       "min           0.000000       0.717000\n",
       "25%           0.000000       8.432000\n",
       "50%           0.000000       9.880000\n",
       "75%           0.000000       9.996000\n",
       "max           0.144700      10.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['precipIntensity', 'visibility']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_severity(row):\n",
    "    # Initialize severity\n",
    "    severity = 1\n",
    "\n",
    "    if 'rain' in row['icon'].strip().lower():\n",
    "        # If rain is present in the icon, check for light or drizzle\n",
    "        if 'light' in row['short_summary'].lower() or 'drizzle' in row['short_summary'].lower() or \\\n",
    "           'light' in row['long_summary'].lower() or 'drizzle' in row['long_summary'].lower():\n",
    "            severity = 2  # Moderate severity for light rain or drizzle\n",
    "        else:\n",
    "            severity = 3  # Highest severity for rain without light or drizzle\n",
    "    elif 'cloudy' in row['icon'].lower() or 'fog' in row['icon'].lower():\n",
    "        severity = 2  # Moderate severity for clouds and fog\n",
    "\n",
    "    # Adjust severity based on visibility\n",
    "    if row['visibility'] < 1:  # Low visibility (less than 1)\n",
    "        severity += 1  # Increase severity by 1\n",
    "    elif row['visibility'] >= 7:  # High visibility (7 or more)\n",
    "        severity -= 1  # Decrease severity by 1\n",
    "        severity = max(severity, 1)  # Ensure severity doesn't go below 1\n",
    "\n",
    "    return severity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-related Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    # Create rush_hour feature\n",
    "    df['rush_hour'] = df['hour'].apply(lambda x: 1 if (6 <= x <= 9 or 16 <= x <= 18) else 0)\n",
    "\n",
    "    # Create weekend feature\n",
    "    df['weekend'] = df['datetime'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "    # Define game dates for Bruins and Celtics\n",
    "    bruins = [\n",
    "        '2018-11-05', '2018-11-08', '2018-11-10', '2018-11-11',\n",
    "        '2018-11-23', '2018-11-29', '2018-12-01', '2018-12-08',\n",
    "        '2018-12-11', '2018-12-16', '2018-12-20', '2018-12-22',\n",
    "        '2018-12-27'\n",
    "    ] \n",
    "    celtics = [\n",
    "        '2018-11-01', '2018-11-14', '2018-11-16', '2018-11-17',\n",
    "        '2018-11-21', '2018-11-30', '2018-12-06', '2018-12-10',\n",
    "        '2018-12-14', '2018-12-19', '2018-12-21', '2018-12-23',\n",
    "        '2018-12-25'\n",
    "    ]\n",
    "    game_dates = bruins + celtics\n",
    "\n",
    "    # Create game_day feature\n",
    "    df['game_day'] = df['datetime'].apply(lambda x: 1 if x.strftime('%Y-%m-%d') in game_dates else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_time_features(train_df)\n",
    "val_df = add_time_features(val_df)\n",
    "test_df = add_time_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Since we conducted feature engineering on the original data before preprocessing, we will run the pipeline again to get the prepare the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Imputation\n",
    "Uber Taxi Fee Breakdown\n",
    " - base fare: $2.60 for first 1/7 mile\n",
    " - per minute fare: $0.47\n",
    " - per mile: $2.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_price_calculator(distance, time):\n",
    "    base_fare = 2.60\n",
    "    per_min_fare = 0.47\n",
    "    per_mile_fare = 2.8\n",
    "    price = base_fare + distance * per_mile_fare + time * per_min_fare\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_with_eta = os.path.join(interim_data_folder, \"rides_with_etas.csv\")\n",
    "\n",
    "time_df = pd.read_csv(rides_with_eta)\n",
    "train_df = pd.merge(train_df, time_df[['source', 'destination', 'eta_minutes']], on=['source', 'destination'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['name'] == 'Taxi', 'price'] = train_df.loc[train_df['name'] == 'Taxi'].apply(\n",
    "    lambda row: taxi_price_calculator(row['distance'], row['eta_minutes']), axis=1)\n",
    "\n",
    "train_df = train_df.drop('eta_minutes', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in 'price' after imputing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "df_na = train_df[train_df['price'].isna()]\n",
    "missing_percentage_after_imputing =train_df['price'].isna().sum() / len(train_df) * 100\n",
    "print(f\"Percentage of missing values in 'price' after imputing: {missing_percentage_after_imputing:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Uneeded Columns\n",
    "Some columns are not relevant for modeling because they function solely as unique identifiers and do not provide meaningful information for preduction purposes:\n",
    "- `id`\n",
    "- `product_id`\n",
    "\n",
    "Additionally, we also dropped `timezone` since all data is within the same timezone.\n",
    "\n",
    "`datetime` and`timestamp` were dropped to reduce redundacy with other time features.\n",
    "\n",
    "`visibility.1` is duplicated with  `visibility`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['timezone', 'datetime', 'product_id', 'visibility.1', 'timestamp','short_summary', 'long_summary', 'icon']\n",
    "\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "val_df = val_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "#### Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Columns:\n",
      "['source', 'destination', 'cab_type', 'name']\n"
     ]
    }
   ],
   "source": [
    "object_columns = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Display the object columns\n",
    "print(\"Object Columns:\")\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Encoding `source` and `destination` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['source'] = train_df['source'].str.strip().str.replace(' ', '_')\n",
    "val_df['source'] = val_df['source'].str.strip().str.replace(' ', '_')\n",
    "test_df['source'] = test_df['source'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'source' column\n",
    "train_encoded_summary = encoder.fit_transform(train_df[['source']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_summary = encoder.transform(val_df[['source']])\n",
    "test_encoded_summary = encoder.transform(test_df[['source']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_summary_df = pd.DataFrame(train_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "val_encoded_summary_df = pd.DataFrame(val_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "test_encoded_summary_df = pd.DataFrame(test_encoded_summary, columns=encoder.get_feature_names_out(['source']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'source' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_summary_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_summary_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the categories from the fitted OneHotEncoder for 'source'\n",
    "source_categories = encoder.categories_[0]\n",
    "\n",
    "# Initialize a new OneHotEncoder for 'destination'\n",
    "destination_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Strip leading/trailing spaces and replace blank spaces with underscores in the destination column\n",
    "train_df['destination'] = train_df['destination'].str.strip().str.replace(' ', '_')\n",
    "val_df['destination'] = val_df['destination'].str.strip().str.replace(' ', '_')\n",
    "test_df['destination'] = test_df['destination'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Fit the encoder on the training data 'destination' column\n",
    "train_encoded_destination = destination_encoder.fit_transform(train_df[['destination']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_destination = destination_encoder.transform(val_df[['destination']])\n",
    "test_encoded_destination = destination_encoder.transform(test_df[['destination']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_destination_df = pd.DataFrame(train_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "val_encoded_destination_df = pd.DataFrame(val_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "test_encoded_destination_df = pd.DataFrame(test_encoded_destination, columns=destination_encoder.get_feature_names_out(['destination']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'destination' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_destination_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_destination_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_destination_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding 'cab_type' and 'name' variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['name'] = train_df['name'].str.strip().str.replace(' ', '_')\n",
    "val_df['name'] = val_df['name'].str.strip().str.replace(' ', '_')\n",
    "test_df['name'] = test_df['name'].str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data 'name' column\n",
    "train_encoded_summary = encoder.fit_transform(train_df[['name']])\n",
    "\n",
    "# Apply the encoder to validation and test sets using the trained categories from the training data\n",
    "val_encoded_summary = encoder.transform(val_df[['name']])\n",
    "test_encoded_summary = encoder.transform(test_df[['name']])\n",
    "\n",
    "# Convert the encoded arrays back to pandas DataFrames with appropriate column names\n",
    "train_encoded_summary_df = pd.DataFrame(train_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "val_encoded_summary_df = pd.DataFrame(val_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "test_encoded_summary_df = pd.DataFrame(test_encoded_summary, columns=encoder.get_feature_names_out(['name']))\n",
    "\n",
    "# Concatenate the one-hot encoded 'name' columns back to the respective datasets\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_summary_df], axis=1)\n",
    "val_df = pd.concat([val_df.reset_index(drop=True), val_encoded_summary_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cab_type'] = train_df['cab_type'].str.strip()\n",
    "val_df['cab_type'] = val_df['cab_type'].str.strip()\n",
    "test_df['cab_type'] = test_df['cab_type'].str.strip()\n",
    "\n",
    "# Ensure there are no leading or trailing spaces in the 'cab_type' column\n",
    "train_df['cab_type'] = train_df['cab_type'].str.strip()\n",
    "val_df['cab_type'] = val_df['cab_type'].str.strip()\n",
    "test_df['cab_type'] = test_df['cab_type'].str.strip()\n",
    "\n",
    "# Create dummy variables for the 'cab_type' column\n",
    "train_df = pd.get_dummies(train_df, columns=['cab_type'], drop_first=True)\n",
    "val_df = pd.get_dummies(val_df, columns=['cab_type'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=['cab_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop encoded categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns_to_drop = ['source',\n",
    " 'destination',\n",
    " 'name']\n",
    "\n",
    "train_df = train_df.drop(columns = cat_columns_to_drop)\n",
    "val_df = val_df.drop(columns = cat_columns_to_drop)\n",
    "test_df = test_df.drop(columns = cat_columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and PCA\n",
    "#### First, let's standardize our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[['price']]\n",
    "y_val = val_df[['price']]\n",
    "y_test = test_df[['price']]\n",
    "\n",
    "X_train = train_df.drop('price', axis = 1)\n",
    "X_val = val_df.drop('price', axis = 1)\n",
    "X_test = test_df.drop('price', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaled DataFrames as Parquet files\n",
    "\n",
    "X_train_scaled_df.to_parquet(os.path.join(processed_data_folder, 'X_train_scaled.parquet'), index=False)\n",
    "X_val_scaled_df.to_parquet(os.path.join(processed_data_folder, 'X_val_scaled.parquet'), index=False)\n",
    "X_test_scaled_df.to_parquet(os.path.join(processed_data_folder, 'X_test_scaled.parquet'), index=False)\n",
    "\n",
    "# Save the target variables (if needed)\n",
    "y_train.to_parquet(os.path.join(processed_data_folder, 'y_train.parquet'), index=False)\n",
    "y_val.to_parquet(os.path.join(processed_data_folder, 'y_val.parquet'), index=False)\n",
    "y_test.to_parquet(os.path.join(processed_data_folder, 'y_test.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA, you can adjust n_components as needed (for example, n_components=0.95 for 95% variance)\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "\n",
    "X_train_scaled = X_train_scaled_df.to_numpy()\n",
    "X_val_scaled = X_val_scaled_df.to_numpy()\n",
    "X_test_scaled = X_test_scaled_df.to_numpy()\n",
    "\n",
    "# Fit PCA on the scaled training data\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Transform the validation and test sets using the same PCA\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Convert the PCA results back to DataFrames for easier handling\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_val_pca_df = pd.DataFrame(X_val_pca)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca)\n",
    "\n",
    "# Optional: Rename the columns for clarity\n",
    "X_train_pca_df.columns = [f'PC{i+1}' for i in range(X_train_pca_df.shape[1])]\n",
    "X_val_pca_df.columns = [f'PC{i+1}' for i in range(X_val_pca_df.shape[1])]\n",
    "X_test_pca_df.columns = [f'PC{i+1}' for i in range(X_test_pca_df.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 45)\n",
      "(20000, 45)\n",
      "(10000, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca_df.shape)\n",
    "print(X_val_pca_df.shape)\n",
    "print(X_test_pca_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA DataFrames as Parquet files\n",
    "train_pca_path = os.path.join(processed_data_folder, 'X_train_pca.parquet')\n",
    "val_pca_path = os.path.join(processed_data_folder, 'X_val_pca.parquet')\n",
    "test_pca_path = os.path.join(processed_data_folder, 'X_test_pca.parquet')\n",
    "\n",
    "X_train_pca_df.to_parquet(train_pca_path, index=False)\n",
    "X_val_pca_df.to_parquet(val_pca_path, index=False)\n",
    "X_test_pca_df.to_parquet(test_pca_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first modeling method we will use is linear regression. We will use ridge regression (L2) to vary the regularization strength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three models with varying regularization strengths\n",
    "ridge_model_1 = Ridge(alpha=0.001)  # low regularization\n",
    "ridge_model_2 = Ridge(alpha=0.01)  # medium regularization\n",
    "ridge_model_3 = Ridge(alpha=1) # high regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train each Ridge model\n",
    "ridge_model_1.fit(X_train_scaled, y_train)\n",
    "ridge_model_2.fit(X_train_scaled, y_train)\n",
    "ridge_model_3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training and validation datasets\n",
    "y_train_pred_1 = ridge_model_1.predict(X_train_scaled)\n",
    "y_val_pred_1 = ridge_model_1.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_2 = ridge_model_2.predict(X_train_scaled)\n",
    "y_val_pred_2 = ridge_model_2.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_3 = ridge_model_3.predict(X_train_scaled)\n",
    "y_val_pred_3 = ridge_model_3.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics (MSE and R-squared) for training and validation datasets\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train_scaled: 0\n",
      "NaN values in X_val_scaled: 0\n",
      "NaN values in y_train: price    0\n",
      "dtype: int64\n",
      "NaN values in y_val: price    1553\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the training and validation sets\n",
    "print(\"NaN values in X_train_scaled:\", np.isnan(X_train_scaled).sum())\n",
    "print(\"NaN values in X_val_scaled:\", np.isnan(X_val_scaled).sum())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).sum())\n",
    "print(\"NaN values in y_val:\", np.isnan(y_val).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Ridge model 1\n",
    "train_mse_1, train_r2_1 = evaluate_model(y_train, y_train_pred_1)\n",
    "#val_mse_1, val_r2_1 = evaluate_model(y_val, y_val_pred_1)\n",
    "\n",
    "# Evaluate Ridge model 2\n",
    "train_mse_2, train_r2_2 = evaluate_model(y_train, y_train_pred_2)\n",
    "#val_mse_2, val_r2_2 = evaluate_model(y_val, y_val_pred_2)\n",
    "\n",
    "# Evaluate Ridge model 3\n",
    "train_mse_3, train_r2_3 = evaluate_model(y_train, y_train_pred_3)\n",
    "#val_mse_3, val_r2_3 = evaluate_model(y_val, y_val_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (alpha=0.1) - Training MSE: 6868.4819, R2: 0.2146\n",
      "Model 2 (alpha=1.0) - Training MSE: 6868.4965, R2: 0.2146\n",
      "Model 3 (alpha=10.0) - Training MSE: 6868.8433, R2: 0.2145\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Model 1 (alpha=0.1) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_1, train_r2_1))\n",
    "#print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_1, val_r2_1))\n",
    "\n",
    "print(\"Model 2 (alpha=1.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_2, train_r2_2))\n",
    "#print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_2, val_r2_2))\n",
    "\n",
    "print(\"Model 3 (alpha=10.0) - Training MSE: {:.4f}, R2: {:.4f}\".format(train_mse_3, train_r2_3))\n",
    "#print(\"Validation MSE: {:.4f}, R2: {:.4f}\".format(val_mse_3, val_r2_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
