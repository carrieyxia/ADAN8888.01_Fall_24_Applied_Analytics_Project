{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Notebook: Model training, hyperparameter tuning, and model evaluation\n",
    "The goal of this week's assignment is to use one modeling method with 3 different hyperparameter settings of the method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_folder = os.path.join(parent_dir,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "interim_data_folder = os.path.join(data_folder,\"interim\")\n",
    "processed_data_folder = os.path.join(data_folder, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA DataFrames as Parquet files\n",
    "X_train_scaled_path = os.path.join(processed_data_folder, 'X_train_scaled.parquet')\n",
    "X_val_scaled_path = os.path.join(processed_data_folder, 'X_val_scaled.parquet')\n",
    "X_test_scaled_path = os.path.join(processed_data_folder, 'X_test_scaled.parquet')\n",
    "\n",
    "# Paths for the target variables\n",
    "y_train_path = os.path.join(processed_data_folder, 'y_train.parquet')\n",
    "y_val_path = os.path.join(processed_data_folder, 'y_val.parquet')\n",
    "y_test_path = os.path.join(processed_data_folder, 'y_test.parquet')\n",
    "\n",
    "train_pca_path = os.path.join(processed_data_folder, 'X_train_pca.parquet')\n",
    "val_pca_path = os.path.join(processed_data_folder, 'X_val_pca.parquet')\n",
    "test_pca_path = os.path.join(processed_data_folder, 'X_test_pca.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.read_parquet(X_train_scaled_path)\n",
    "X_val_scaled = pd.read_parquet(X_val_scaled_path)\n",
    "X_test_scaled = pd.read_parquet(X_test_scaled_path)\n",
    "\n",
    "# Reading the target variables\n",
    "y_train = pd.read_parquet(y_train_path)\n",
    "y_val = pd.read_parquet(y_val_path)\n",
    "y_test = pd.read_parquet(y_test_path)\n",
    "\n",
    "X_train_pca = pd.read_parquet(train_pca_path)\n",
    "X_val_pca = pd.read_parquet(val_pca_path)\n",
    "X_test_pca = pd.read_parquet(test_pca_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression Model - Metrics:\n",
      "MSE: 5561174730553425232134144.0000, RMSE: 2358214309716.8726, R²: -524252598994980569088.0000\n"
     ]
    }
   ],
   "source": [
    "ols = LinearRegression()\n",
    "\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "ols_predictions = ols.predict(X_test_scaled)\n",
    "\n",
    "ols_mse, ols_rmse, ols_r2 = evaluate_model(y_test, ols_predictions)\n",
    "\n",
    "print(\"OLS Regression Model - Metrics:\")\n",
    "print(f\"MSE: {ols_mse:.4f}, RMSE: {ols_rmse:.4f}, R²: {ols_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS PCA Regression Model - Metrics:\n",
      "MSE: 8009.1325, RMSE: 89.4938, R²: 0.2450\n"
     ]
    }
   ],
   "source": [
    "ols_pca = LinearRegression()\n",
    "\n",
    "ols_pca.fit(X_train_pca, y_train)\n",
    "ols_pca_predictions = ols_pca.predict(X_test_pca)\n",
    "\n",
    "ols_pca_mse, ols_pca_rmse, ols_pca_r2 = evaluate_model(y_test, ols_pca_predictions)\n",
    "\n",
    "\n",
    "print(\"OLS PCA Regression Model - Metrics:\")\n",
    "print(f\"MSE: {ols_pca_mse:.4f}, RMSE: {ols_pca_rmse:.4f}, R²: {ols_pca_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+08, tolerance: 4.896e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+08, tolerance: 4.862e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+08, tolerance: 4.971e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+08, tolerance: 5.004e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+08, tolerance: 4.753e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.563e+05, tolerance: 4.862e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+06, tolerance: 4.971e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.595e+05, tolerance: 5.004e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Lasso: 0.1\n"
     ]
    }
   ],
   "source": [
    "lasso_alphas = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}  \n",
    "\n",
    "lasso = Lasso()\n",
    "lasso_cv = GridSearchCV(lasso, param_grid=lasso_alphas, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_lasso_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Lasso: {best_lasso_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Model - Training Metrics:\n",
      "MSE: 6871.0827, RMSE: 82.8920, R²: 0.2143\n",
      "\n",
      "Lasso Regression Model - Testing Metrics:\n",
      "MSE: 8008.4404, RMSE: 89.4899, R²: 0.2450\n"
     ]
    }
   ],
   "source": [
    "lasso_best = Lasso(alpha=best_lasso_alpha)\n",
    "lasso_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the training and testing data\n",
    "y_train_pred_lasso = lasso_best.predict(X_train_scaled)\n",
    "y_test_pred_lasso = lasso_best.predict(X_test_scaled)\n",
    "\n",
    "# Use the evaluate_model function to calculate MSE, RMSE, and R²\n",
    "train_mse_lasso, train_rmse_lasso, train_r2_lasso = evaluate_model(y_train, y_train_pred_lasso)\n",
    "test_mse_lasso, test_rmse_lasso, test_r2_lasso = evaluate_model(y_test, y_test_pred_lasso)\n",
    "\n",
    "# Print the results for the training and testing datasets\n",
    "print(\"Lasso Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_lasso:.4f}, RMSE: {train_rmse_lasso:.4f}, R²: {train_r2_lasso:.4f}\")\n",
    "\n",
    "print(\"\\nLasso Regression Model - Testing Metrics:\")\n",
    "print(f\"MSE: {test_mse_lasso:.4f}, RMSE: {test_rmse_lasso:.4f}, R²: {test_r2_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: 0.1\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge_alphas = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}  # Define alpha range\n",
    "ridge_cv = GridSearchCV(ridge, param_grid=ridge_alphas, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "best_ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Ridge: {best_ridge_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model - Training Metrics:\n",
      "MSE: 6866.5889, RMSE: 82.8649, R²: 0.2148\n",
      "\n",
      "Ridge Regression Model - Testing Metrics:\n",
      "MSE: 8013.6327, RMSE: 89.5189, R²: 0.2446\n"
     ]
    }
   ],
   "source": [
    "ridge_best = Ridge(alpha=best_ridge_alpha)\n",
    "ridge_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred_ridge = ridge_best.predict(X_train_scaled)\n",
    "y_test_pred_ridge = ridge_best.predict(X_test_scaled)\n",
    "\n",
    "train_mse_ridge, train_rmse_ridge, train_r2_ridge = evaluate_model(y_train, y_train_pred_ridge)\n",
    "test_mse_ridge, test_rmse_ridge, test_r2_ridge = evaluate_model(y_test, y_test_pred_ridge)\n",
    "\n",
    "# Step 4: Print the results for the training and testing datasets\n",
    "print(\"Ridge Regression Model - Training Metrics:\")\n",
    "print(f\"MSE: {train_mse_ridge:.4f}, RMSE: {train_rmse_ridge:.4f}, R²: {train_r2_ridge:.4f}\")\n",
    "\n",
    "print(\"\\nRidge Regression Model - Testing Metrics:\")\n",
    "print(f\"MSE: {test_mse_ridge:.4f}, RMSE: {test_rmse_ridge:.4f}, R²: {test_r2_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with polynomial terms\n",
    "We commented out this part to save memories when running on JupyterHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Model - Training Metrics:\n",
      "MSE: 2.7317, RMSE: 1.6528, R2: 0.9997\n",
      "\n",
      "Polynomial Regression Model - Validation Metrics:\n",
      "MSE: 49686456322655606800384.0000, RMSE: 222904590178.5237, R2: -6096575569854032896.0000\n"
     ]
    }
   ],
   "source": [
    "# poly = PolynomialFeatures(degree=2)  # Adjust the degree as needed\n",
    "# X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "# X_val_poly = poly.transform(X_val_scaled)\n",
    "\n",
    "# # Step 2: Fit the Linear Regression model\n",
    "# poly_model = LinearRegression()\n",
    "# poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# # Step 3: Make predictions\n",
    "# y_train_pred_poly = poly_model.predict(X_train_poly)\n",
    "# y_val_pred_poly = poly_model.predict(X_val_poly)\n",
    "\n",
    "# # Step 4: Calculate evaluation metrics (MSE and R-squared)\n",
    "# train_mse_poly, train_rmse_poly, train_r2_poly = evaluate_model(y_train, y_train_pred_poly)\n",
    "# val_mse_poly, val_rmse_poly, val_r2_poly = evaluate_model(y_val, y_val_pred_poly)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Polynomial Regression Model - Training Metrics:\")\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R2: {:.4f}\".format(train_mse_poly, train_rmse_poly, train_r2_poly))\n",
    "\n",
    "# print(\"\\nPolynomial Regression Model - Validation Metrics:\")\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R2: {:.4f}\".format(val_mse_poly, val_rmse_poly, val_r2_poly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: 0.1\n",
      "Ridge Regression Model (Best alpha=0.1) - Training Metrics:\n",
      "MSE: 2.7311, RMSE: 1.6526, R²: 0.9997\n",
      "Validation Metrics:\n",
      "MSE: 9.1598, RMSE: 3.0265, R²: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# ridge_poly_alphas = {'alpha': [0.01, 0.1, 1]} \n",
    "\n",
    "# ridge = Ridge()\n",
    "\n",
    "# # Step 3: Set up GridSearchCV for cross-validation\n",
    "# ridge_cv = GridSearchCV(ridge, param_grid = ridge_poly_alphas, cv = 5, scoring='neg_mean_squared_error')\n",
    "# ridge_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "# # Get the best alpha value from cross-validation\n",
    "# best_ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "# print(f\"Best alpha for Ridge: {best_ridge_alpha}\")\n",
    "\n",
    "# # Step 4: Fit the Ridge regression model with the best alpha\n",
    "# ridge_best = Ridge(alpha=best_ridge_alpha)\n",
    "# ridge_best.fit(X_train_poly, y_train)\n",
    "\n",
    "# # Step 5: Make predictions\n",
    "# y_train_pred_ridge = ridge_best.predict(X_train_poly)\n",
    "# y_val_pred_ridge = ridge_best.predict(X_val_poly)\n",
    "\n",
    "# # Step 6: Calculate evaluation metrics (MSE, RMSE, R²) using the evaluate function\n",
    "# train_mse_ridge, train_rmse_ridge, train_r2_ridge = evaluate_model(y_train, y_train_pred_ridge)\n",
    "# val_mse_ridge, val_rmse_ridge, val_r2_ridge = evaluate_model(y_val, y_val_pred_ridge)\n",
    "\n",
    "# # Print results for the best Ridge model\n",
    "# print(\"Ridge Regression Model (Best alpha={}) - Training Metrics:\".format(best_ridge_alpha))\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}\".format(train_mse_ridge, train_rmse_ridge, train_r2_ridge))\n",
    "# print(\"Validation Metrics:\")\n",
    "# print(\"MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}\".format(val_mse_ridge, val_rmse_ridge, val_r2_ridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
